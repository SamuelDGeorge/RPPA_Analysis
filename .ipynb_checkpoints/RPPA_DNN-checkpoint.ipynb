{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#All neccesary classes for project\n",
    "\n",
    "#general\n",
    "import seaborn as sns\n",
    "import scipy.stats as ss\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "#for preprocessing\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "import tensorflow as tf\n",
    "\n",
    "#for machine learning\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import expon, reciprocal\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "#for evaluation\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "#for utility packages\n",
    "from Utilities.utilities import import_data\n",
    "from Utilities.utilities import DataFrameSelector\n",
    "from Utilities.utilities import CategoricalEncoder\n",
    "from Utilities.utilities import display_scores\n",
    "from Utilities.utilities import pipeline_transform\n",
    "from Utilities.utilities import log_dir\n",
    "from Utilities.utilities import reset_graph\n",
    "from Utilities.utilities import random_batch\n",
    "from Utilities.utilities import random_batch_array\n",
    "from Utilities.models import DNN_Model\n",
    "from Utilities.models import cross_val_score_dnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Format Data\n",
    "\n",
    "Put the data in the proper format for building DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.90078582, -0.95802308, -1.00716855, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.74110481,  1.04381619, -1.00716855, ...,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [-0.7690121 ,  1.04381619,  0.99288247, ...,  1.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ...,\n",
       "       [-0.48063672, -0.95802308,  0.99288247, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 1.90078582, -0.95802308,  0.99288247, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.48063672,  1.04381619, -1.00716855, ...,  0.        ,\n",
       "         0.        ,  1.        ]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Make a dataset\n",
    "raw_data = import_data(\"cleaned_factored_2_1.csv\", \"C:/Users/sdgeo/Dropbox/Der Lab/Data/IremRPPA/raw_data\")\n",
    "\n",
    "#Build for a 4 way classifier\n",
    "raw_data_all = raw_data.copy()\n",
    "raw_data_all[\"treatment\"] = raw_data[\"ly3\"] + raw_data[\"sch\"]\n",
    "\n",
    "raw_data_all[\"treatment\"] = raw_data_all[\"treatment\"].replace([0], 'DMSO')\n",
    "raw_data_all[\"treatment\"] = raw_data_all[\"treatment\"].replace([40], 'SCH')\n",
    "raw_data_all[\"treatment\"] = raw_data_all[\"treatment\"].replace([300], 'LY3')\n",
    "raw_data_all[\"treatment\"] = raw_data_all[\"treatment\"].replace([340], 'COMBO')\n",
    "\n",
    "#Make training and data set\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=42)\n",
    "for train_index, test_index in split.split(raw_data_all, raw_data_all[\"cell.line\"]):\n",
    "    strat_train_set_all = raw_data_all.loc[train_index]\n",
    "    strat_test_set_all = raw_data_all.loc[test_index]\n",
    "    \n",
    "#Try to distinguish all 4\n",
    "raw_train_treatment = strat_train_set_all.drop(\"treatment\", axis=1).reset_index().drop(\"index\", axis=1)\n",
    "raw_train_labels_treatment = strat_train_set_all[\"treatment\"].copy().reset_index().drop(\"index\", axis=1)\n",
    "\n",
    "raw_test_treatment = strat_test_set_all.drop(\"treatment\", axis=1).reset_index().drop(\"index\", axis=1)\n",
    "raw_test_labels_treatment = strat_test_set_all[\"treatment\"].copy().reset_index().drop(\"index\", axis=1)\n",
    "\n",
    "#convert the labels into a numeric\n",
    "raw_train_labels_tensor = pd.DataFrame(raw_train_labels_treatment['treatment'].replace(['DMSO'], 0))\n",
    "raw_train_labels_tensor = pd.DataFrame(raw_train_labels_tensor['treatment'].replace(['SCH'], 1))\n",
    "raw_train_labels_tensor = pd.DataFrame(raw_train_labels_tensor['treatment'].replace(['LY3'], 2))\n",
    "train_treatment_labels_tensor = pd.DataFrame(raw_train_labels_tensor['treatment'].replace(['COMBO'], 3)).as_matrix()[:,0]\n",
    "\n",
    "raw_test_labels_tensor = pd.DataFrame(raw_test_labels_treatment['treatment'].replace(['DMSO'], 0))\n",
    "raw_test_labels_tensor = pd.DataFrame(raw_test_labels_tensor['treatment'].replace(['SCH'], 1))\n",
    "raw_test_labels_tensor = pd.DataFrame(raw_test_labels_tensor['treatment'].replace(['LY3'], 2))\n",
    "test_treatment_labels_tensor = pd.DataFrame(raw_test_labels_tensor['treatment'].replace(['COMBO'], 3)).as_matrix()[:,0]\n",
    "\n",
    "#Treatment\n",
    "train_treatment_tensor = pipeline_transform(raw_train_treatment, scaler=True).as_matrix()\n",
    "test_treatment_tensor = pipeline_transform(raw_test_treatment, scaler=True).as_matrix()\n",
    "\n",
    "train_treatment_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build the graph\n",
    "reset_graph()\n",
    "from datetime import datetime\n",
    "from functools import partial\n",
    "\n",
    "with tf.device('/device:CPU:0'):\n",
    "    n_inputs = len(train_treatment_tensor[0])\n",
    "    n_hidden1 = n_inputs\n",
    "    n_hidden2 = 100\n",
    "    n_hidden3 = 50\n",
    "    n_outputs = 4\n",
    "    dropout_rate = 0.5\n",
    "\n",
    "    #training data placeholder\n",
    "    X = tf.placeholder(tf.float32, shape = (None, n_inputs), name=\"X\")\n",
    "    y = tf.placeholder(tf.int64, shape=(None), name = \"y\")\n",
    "    \n",
    "\n",
    "    training = tf.placeholder_with_default(False, shape=(), name = 'training')\n",
    "\n",
    "    #he_init = tf.contrib.layers.variance_scaling_initializer()\n",
    "    bn_batch_norm_layer = partial(tf.layers.batch_normalization, training=training, momentum=0.9)\n",
    "    he_init = tf.contrib.layers.variance_scaling_initializer()\n",
    "\n",
    "    #using tensorflow\n",
    "    with tf.name_scope(\"dnn\"):\n",
    "        X_dropout = tf.layers.dropout(X, dropout_rate, training=training)\n",
    "        hidden1 = tf.layers.dense(X, n_hidden1, name=\"hidden1\", kernel_initializer=he_init)\n",
    "        hidden1_drop = tf.layers.dropout(hidden1, dropout_rate, training=training)\n",
    "        bn1 = bn_batch_norm_layer(hidden1_drop)\n",
    "        bn1_act = tf.nn.elu(bn1)\n",
    "    \n",
    "        hidden2 = tf.layers.dense(bn1_act, n_hidden2, name=\"hidden2\", kernel_initializer=he_init)\n",
    "        hidden2_drop = tf.layers.dropout(hidden2, dropout_rate, training=training)\n",
    "        bn2 = bn_batch_norm_layer(hidden2_drop)\n",
    "        bn2_act = tf.nn.elu(bn2)\n",
    "    \n",
    "        hidden3 = tf.layers.dense(bn2_act, n_hidden3, name=\"hidden3\", kernel_initializer=he_init)\n",
    "        hidden3_drop = tf.layers.dropout(hidden3, dropout_rate, training=training)\n",
    "        bn3 = bn_batch_norm_layer(hidden3_drop)\n",
    "        bn3_act = tf.nn.elu(bn3)\n",
    "    \n",
    "        logits_before_bn = tf.layers.dense(bn3_act, n_outputs, name=\"outputs\")\n",
    "        logits = bn_batch_norm_layer(logits_before_bn)\n",
    "    \n",
    "#Calculate the loss out fo the last layer\n",
    "\n",
    "    with tf.name_scope(\"loss\"):\n",
    "        xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "        loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "    \n",
    "#Describe a way to train\n",
    "\n",
    "    learning_rate = 0.01\n",
    "    with tf.name_scope(\"train\"):\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "        training_op = optimizer.minimize(loss)\n",
    "    \n",
    "    #Evaluate the model\n",
    "    with tf.name_scope(\"eval\"):\n",
    "        correct = tf.nn.in_top_k(logits, y, 1)\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "        accuracy_summary = tf.summary.scalar('accuracy', accuracy)\n",
    " \n",
    "    #make initializer and saver\n",
    "    init = tf.global_variables_initializer()\n",
    "    saver = tf.train.Saver()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execution Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train accuracy: 0.4 Val accuracy: 0.333333\n",
      "1 Train accuracy: 0.0 Val accuracy: 0.35\n",
      "2 Train accuracy: 0.4 Val accuracy: 0.325\n",
      "3 Train accuracy: 0.6 Val accuracy: 0.525\n",
      "4 Train accuracy: 0.2 Val accuracy: 0.441667\n",
      "5 Train accuracy: 0.6 Val accuracy: 0.508333\n",
      "6 Train accuracy: 0.8 Val accuracy: 0.508333\n",
      "7 Train accuracy: 0.8 Val accuracy: 0.575\n",
      "8 Train accuracy: 0.6 Val accuracy: 0.566667\n",
      "9 Train accuracy: 0.6 Val accuracy: 0.6\n",
      "10 Train accuracy: 1.0 Val accuracy: 0.591667\n",
      "11 Train accuracy: 0.8 Val accuracy: 0.633333\n",
      "12 Train accuracy: 0.8 Val accuracy: 0.625\n",
      "13 Train accuracy: 0.8 Val accuracy: 0.725\n",
      "14 Train accuracy: 1.0 Val accuracy: 0.825\n",
      "15 Train accuracy: 1.0 Val accuracy: 0.85\n",
      "16 Train accuracy: 1.0 Val accuracy: 0.816667\n",
      "17 Train accuracy: 1.0 Val accuracy: 0.916667\n",
      "18 Train accuracy: 0.8 Val accuracy: 0.916667\n",
      "19 Train accuracy: 0.8 Val accuracy: 0.8\n",
      "20 Train accuracy: 0.8 Val accuracy: 0.816667\n",
      "21 Train accuracy: 1.0 Val accuracy: 0.883333\n",
      "22 Train accuracy: 1.0 Val accuracy: 0.816667\n",
      "23 Train accuracy: 1.0 Val accuracy: 0.925\n",
      "24 Train accuracy: 1.0 Val accuracy: 0.925\n",
      "25 Train accuracy: 1.0 Val accuracy: 0.941667\n",
      "26 Train accuracy: 1.0 Val accuracy: 0.933333\n",
      "27 Train accuracy: 0.8 Val accuracy: 0.875\n",
      "28 Train accuracy: 1.0 Val accuracy: 0.941667\n",
      "29 Train accuracy: 1.0 Val accuracy: 0.95\n",
      "30 Train accuracy: 0.8 Val accuracy: 0.833333\n",
      "31 Train accuracy: 1.0 Val accuracy: 0.891667\n",
      "32 Train accuracy: 1.0 Val accuracy: 0.875\n",
      "33 Train accuracy: 1.0 Val accuracy: 0.941667\n",
      "34 Train accuracy: 0.8 Val accuracy: 0.866667\n",
      "35 Train accuracy: 1.0 Val accuracy: 0.941667\n",
      "36 Train accuracy: 1.0 Val accuracy: 0.966667\n",
      "37 Train accuracy: 0.6 Val accuracy: 0.875\n",
      "38 Train accuracy: 1.0 Val accuracy: 0.933333\n",
      "39 Train accuracy: 1.0 Val accuracy: 0.958333\n",
      "40 Train accuracy: 0.8 Val accuracy: 0.95\n",
      "41 Train accuracy: 1.0 Val accuracy: 0.983333\n",
      "42 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "43 Train accuracy: 1.0 Val accuracy: 0.991667\n",
      "44 Train accuracy: 1.0 Val accuracy: 0.975\n",
      "45 Train accuracy: 1.0 Val accuracy: 0.983333\n",
      "46 Train accuracy: 1.0 Val accuracy: 0.983333\n",
      "47 Train accuracy: 1.0 Val accuracy: 0.975\n",
      "48 Train accuracy: 1.0 Val accuracy: 0.983333\n",
      "49 Train accuracy: 1.0 Val accuracy: 0.983333\n",
      "50 Train accuracy: 1.0 Val accuracy: 0.991667\n",
      "51 Train accuracy: 1.0 Val accuracy: 0.991667\n",
      "52 Train accuracy: 1.0 Val accuracy: 0.95\n",
      "53 Train accuracy: 1.0 Val accuracy: 0.966667\n",
      "54 Train accuracy: 1.0 Val accuracy: 0.966667\n",
      "55 Train accuracy: 1.0 Val accuracy: 0.975\n",
      "56 Train accuracy: 1.0 Val accuracy: 0.991667\n",
      "57 Train accuracy: 1.0 Val accuracy: 0.991667\n",
      "58 Train accuracy: 1.0 Val accuracy: 0.983333\n",
      "59 Train accuracy: 1.0 Val accuracy: 0.975\n",
      "60 Train accuracy: 1.0 Val accuracy: 0.958333\n",
      "61 Train accuracy: 1.0 Val accuracy: 0.975\n",
      "62 Train accuracy: 1.0 Val accuracy: 0.991667\n",
      "63 Train accuracy: 1.0 Val accuracy: 0.983333\n",
      "64 Train accuracy: 1.0 Val accuracy: 0.991667\n",
      "65 Train accuracy: 1.0 Val accuracy: 0.983333\n",
      "66 Train accuracy: 1.0 Val accuracy: 0.983333\n",
      "67 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "68 Train accuracy: 1.0 Val accuracy: 0.991667\n",
      "69 Train accuracy: 1.0 Val accuracy: 0.983333\n",
      "70 Train accuracy: 0.8 Val accuracy: 0.975\n",
      "71 Train accuracy: 1.0 Val accuracy: 0.991667\n",
      "72 Train accuracy: 1.0 Val accuracy: 0.991667\n",
      "73 Train accuracy: 1.0 Val accuracy: 0.983333\n",
      "74 Train accuracy: 1.0 Val accuracy: 0.975\n",
      "75 Train accuracy: 1.0 Val accuracy: 0.991667\n",
      "76 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "77 Train accuracy: 1.0 Val accuracy: 0.983333\n",
      "78 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "79 Train accuracy: 1.0 Val accuracy: 0.991667\n",
      "80 Train accuracy: 1.0 Val accuracy: 0.975\n",
      "81 Train accuracy: 1.0 Val accuracy: 0.983333\n",
      "82 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "83 Train accuracy: 1.0 Val accuracy: 0.975\n",
      "84 Train accuracy: 1.0 Val accuracy: 0.975\n",
      "85 Train accuracy: 1.0 Val accuracy: 0.958333\n",
      "86 Train accuracy: 1.0 Val accuracy: 0.966667\n",
      "87 Train accuracy: 1.0 Val accuracy: 0.966667\n",
      "88 Train accuracy: 1.0 Val accuracy: 0.933333\n",
      "89 Train accuracy: 1.0 Val accuracy: 0.966667\n",
      "90 Train accuracy: 1.0 Val accuracy: 0.983333\n",
      "91 Train accuracy: 1.0 Val accuracy: 0.983333\n",
      "92 Train accuracy: 1.0 Val accuracy: 0.966667\n",
      "93 Train accuracy: 1.0 Val accuracy: 0.983333\n",
      "94 Train accuracy: 1.0 Val accuracy: 0.991667\n",
      "95 Train accuracy: 1.0 Val accuracy: 0.991667\n",
      "96 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "97 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "98 Train accuracy: 1.0 Val accuracy: 0.966667\n",
      "99 Train accuracy: 1.0 Val accuracy: 0.983333\n",
      "100 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "101 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "102 Train accuracy: 1.0 Val accuracy: 0.991667\n",
      "103 Train accuracy: 1.0 Val accuracy: 0.983333\n",
      "104 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "105 Train accuracy: 1.0 Val accuracy: 0.991667\n",
      "106 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "107 Train accuracy: 1.0 Val accuracy: 0.983333\n",
      "108 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "109 Train accuracy: 1.0 Val accuracy: 0.991667\n",
      "110 Train accuracy: 1.0 Val accuracy: 0.991667\n",
      "111 Train accuracy: 1.0 Val accuracy: 0.991667\n",
      "112 Train accuracy: 1.0 Val accuracy: 0.983333\n",
      "113 Train accuracy: 1.0 Val accuracy: 0.991667\n",
      "114 Train accuracy: 1.0 Val accuracy: 0.991667\n",
      "115 Train accuracy: 1.0 Val accuracy: 0.983333\n",
      "116 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "117 Train accuracy: 1.0 Val accuracy: 0.991667\n",
      "118 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "119 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "120 Train accuracy: 1.0 Val accuracy: 0.991667\n",
      "121 Train accuracy: 1.0 Val accuracy: 0.966667\n",
      "122 Train accuracy: 1.0 Val accuracy: 0.991667\n",
      "123 Train accuracy: 1.0 Val accuracy: 0.991667\n",
      "124 Train accuracy: 1.0 Val accuracy: 0.983333\n",
      "125 Train accuracy: 1.0 Val accuracy: 0.991667\n",
      "126 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "127 Train accuracy: 1.0 Val accuracy: 0.983333\n",
      "128 Train accuracy: 1.0 Val accuracy: 0.991667\n",
      "129 Train accuracy: 1.0 Val accuracy: 0.983333\n",
      "130 Train accuracy: 1.0 Val accuracy: 0.991667\n",
      "131 Train accuracy: 1.0 Val accuracy: 0.991667\n",
      "132 Train accuracy: 1.0 Val accuracy: 0.991667\n",
      "133 Train accuracy: 1.0 Val accuracy: 0.983333\n",
      "134 Train accuracy: 1.0 Val accuracy: 0.983333\n",
      "135 Train accuracy: 1.0 Val accuracy: 0.983333\n",
      "136 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "137 Train accuracy: 1.0 Val accuracy: 0.991667\n",
      "138 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "139 Train accuracy: 1.0 Val accuracy: 0.975\n",
      "140 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "141 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "142 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "143 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "144 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "145 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "146 Train accuracy: 1.0 Val accuracy: 0.991667\n",
      "147 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "148 Train accuracy: 0.8 Val accuracy: 1.0\n",
      "149 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "150 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "151 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "152 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "153 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "154 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "155 Train accuracy: 1.0 Val accuracy: 0.991667\n",
      "156 Train accuracy: 1.0 Val accuracy: 0.991667\n",
      "157 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "158 Train accuracy: 1.0 Val accuracy: 0.983333\n",
      "159 Train accuracy: 1.0 Val accuracy: 0.991667\n",
      "160 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "161 Train accuracy: 1.0 Val accuracy: 0.991667\n",
      "162 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "163 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "164 Train accuracy: 1.0 Val accuracy: 0.975\n",
      "165 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "166 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "167 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "168 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "169 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "170 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "171 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "172 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "173 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "174 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "175 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "176 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "177 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "178 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "179 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "180 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "181 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "182 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "183 Train accuracy: 1.0 Val accuracy: 0.991667\n",
      "184 Train accuracy: 1.0 Val accuracy: 0.991667\n",
      "185 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "186 Train accuracy: 1.0 Val accuracy: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187 Train accuracy: 1.0 Val accuracy: 0.991667\n",
      "188 Train accuracy: 1.0 Val accuracy: 0.991667\n",
      "189 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "190 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "191 Train accuracy: 1.0 Val accuracy: 0.991667\n",
      "192 Train accuracy: 1.0 Val accuracy: 0.991667\n",
      "193 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "194 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "195 Train accuracy: 1.0 Val accuracy: 0.983333\n",
      "196 Train accuracy: 1.0 Val accuracy: 0.991667\n",
      "197 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "198 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "199 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "0:00:25.397637\n"
     ]
    }
   ],
   "source": [
    "#set up logging\n",
    "logdir = log_dir(\"/Users/sdgeo/Dropbox/Der Lab/Data/IremRPPA/tf_test\", \"dnn_batch\")\n",
    "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())\n",
    "\n",
    "n_epochs = 200\n",
    "batch_size = 5\n",
    "extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "\n",
    "with tf.Session(config=tf.ConfigProto(log_device_placement=True)) as sess:\n",
    "    start = datetime.utcnow()\n",
    "    current_best = 0\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(len(train_treatment_tensor) // batch_size):\n",
    "            X_batch, y_batch = random_batch(train_treatment_tensor, train_treatment_labels_tensor, batch_size)\n",
    "            sess.run([training_op, extra_update_ops],feed_dict={training: True, X: X_batch, y: y_batch})\n",
    "        acc_train = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "        \n",
    "        acc_val, acc_sum = sess.run([accuracy, accuracy_summary],feed_dict={X: test_treatment_tensor, y: test_treatment_labels_tensor})\n",
    "        file_writer.add_summary(acc_sum, epoch)\n",
    "        if (acc_val > current_best):\n",
    "            current_best = acc_val\n",
    "            saver.save(sess, \"/tmp/test/rppa_model_current_best_dropout_final.ckpt\")\n",
    "        print(epoch, \"Train accuracy:\", acc_train, \"Val accuracy:\", acc_val)\n",
    "        \n",
    "    print(datetime.utcnow() - start)\n",
    "        \n",
    "file_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"/tmp/test/rppa_model_current_best_dropout_final.ckpt\")\n",
    "    X_new_scaled = test_tensor\n",
    "    #X_new_scaled, y = random_batch(train_treatment_tensor, raw_train_labels_tensor, batch_size)\n",
    "    #X_new_scaled.as_matrix()\n",
    "    y_raw = logits.eval(feed_dict={training: False, X: X_new_scaled})\n",
    "    y_pred = np.argmax(y_raw, axis=1)\n",
    "    \n",
    "f1_score(y_pred, raw_test_labels_tensor_final, average='macro')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimentation\n",
    "\n",
    "How to use a queue to put all the data in a Queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build the graph\n",
    "reset_graph()\n",
    "from datetime import datetime\n",
    "from functools import partial\n",
    "\n",
    "n_inputs = len(train_treatment_tensor[0])\n",
    "n_epochs = 200\n",
    "num_batches = len(train_treatment_tensor) // batch_size\n",
    "n_hidden1 = n_inputs\n",
    "n_hidden2 = 100\n",
    "n_hidden3 = 50\n",
    "n_outputs = 4\n",
    "batch_size = 10\n",
    "dropout_rate = 0.5\n",
    "\n",
    "with tf.device(\"/gpu:0\"):\n",
    "    #q = tf.FIFOQueue(capacity=num_batches * n_epochs, dtypes=[tf.float32, tf.int64], \n",
    "    #                 shapes=[(batch_size, n_inputs), (batch_size)], name=\"data\", shared_name=\"shared_data\")\n",
    "    #q = tf.RandomShuffleQueue(capacity=num_batches * n_epochs, dtypes=[tf.float32, tf.int64], \n",
    "    #                 shapes=[(batch_size, n_inputs), (batch_size)], name=\"data\", shared_name=\"shared_data\")\n",
    "    q = tf.PaddingFIFOQueue(capacity=num_batches * n_epochs, dtypes=[tf.float32, tf.int64], \n",
    "                     shapes=[[None, n_inputs],[None]], name=\"data\", shared_name=\"shared_data\")\n",
    "    \n",
    "    #training data placeholder\n",
    "    X_input = tf.placeholder(tf.float32, shape = (None, n_inputs), name=\"X_input\")\n",
    "    y_input = tf.placeholder(tf.int64, shape=(None), name = \"y_input\")\n",
    "    enqueue = q.enqueue([X_input,y_input])\n",
    "    close_q = q.close()\n",
    "    \n",
    "    X_out, y_out = q.dequeue()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape = (None, n_inputs), name=\"X_input\")\n",
    "y = tf.placeholder(tf.int64, shape=(None), name = \"y_input\")\n",
    "\n",
    "training = tf.placeholder_with_default(False, shape=(), name = 'training')\n",
    "\n",
    "#he_init = tf.contrib.layers.variance_scaling_initializer()\n",
    "bn_batch_norm_layer = partial(tf.layers.batch_normalization, training=training, momentum=0.9)\n",
    "he_init = tf.contrib.layers.variance_scaling_initializer()\n",
    "\n",
    " #using tensorflow\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    X_dropout = tf.layers.dropout(X, dropout_rate, training=training)\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, name=\"hidden1\", kernel_initializer=he_init)\n",
    "    hidden1_drop = tf.layers.dropout(hidden1, dropout_rate, training=training)\n",
    "    bn1 = bn_batch_norm_layer(hidden1_drop)\n",
    "    bn1_act = tf.nn.elu(bn1)\n",
    "    \n",
    "    hidden2 = tf.layers.dense(bn1_act, n_hidden2, name=\"hidden2\", kernel_initializer=he_init)\n",
    "    hidden2_drop = tf.layers.dropout(hidden2, dropout_rate, training=training)\n",
    "    bn2 = bn_batch_norm_layer(hidden2_drop)\n",
    "    bn2_act = tf.nn.elu(bn2)\n",
    "    \n",
    "    hidden3 = tf.layers.dense(bn2_act, n_hidden3, name=\"hidden3\", kernel_initializer=he_init)\n",
    "    hidden3_drop = tf.layers.dropout(hidden3, dropout_rate, training=training)\n",
    "    bn3 = bn_batch_norm_layer(hidden3_drop)\n",
    "    bn3_act = tf.nn.elu(bn3)\n",
    "    \n",
    "    logits_before_bn = tf.layers.dense(bn3_act, n_outputs, name=\"outputs\")\n",
    "    logits = bn_batch_norm_layer(logits_before_bn)\n",
    "    \n",
    "#Calculate the loss out fo the last layer\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "    \n",
    "#Describe a way to train\n",
    "\n",
    "learning_rate = 0.01\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "    \n",
    " #Evaluate the model\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "    accuracy_summary = tf.summary.scalar('accuracy', accuracy)\n",
    " \n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train accuracy: 0.5 Val accuracy: 0.44166666\n",
      "1 Train accuracy: 0.8 Val accuracy: 0.6166667\n",
      "2 Train accuracy: 0.7 Val accuracy: 0.76666665\n",
      "3 Train accuracy: 0.9 Val accuracy: 0.85\n",
      "4 Train accuracy: 0.8 Val accuracy: 0.8833333\n",
      "5 Train accuracy: 1.0 Val accuracy: 0.975\n",
      "6 Train accuracy: 1.0 Val accuracy: 0.975\n",
      "7 Train accuracy: 1.0 Val accuracy: 0.95\n",
      "8 Train accuracy: 1.0 Val accuracy: 0.96666664\n",
      "9 Train accuracy: 1.0 Val accuracy: 0.96666664\n",
      "10 Train accuracy: 1.0 Val accuracy: 0.93333334\n",
      "11 Train accuracy: 1.0 Val accuracy: 0.9916667\n",
      "12 Train accuracy: 1.0 Val accuracy: 0.96666664\n",
      "13 Train accuracy: 1.0 Val accuracy: 0.98333335\n",
      "14 Train accuracy: 1.0 Val accuracy: 0.9916667\n",
      "15 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "16 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "17 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "18 Train accuracy: 1.0 Val accuracy: 0.975\n",
      "19 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "20 Train accuracy: 1.0 Val accuracy: 0.975\n",
      "21 Train accuracy: 1.0 Val accuracy: 0.9916667\n",
      "22 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "23 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "24 Train accuracy: 1.0 Val accuracy: 0.975\n",
      "25 Train accuracy: 1.0 Val accuracy: 0.9916667\n",
      "26 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "27 Train accuracy: 1.0 Val accuracy: 0.9916667\n",
      "28 Train accuracy: 1.0 Val accuracy: 0.9916667\n",
      "29 Train accuracy: 1.0 Val accuracy: 0.98333335\n",
      "30 Train accuracy: 1.0 Val accuracy: 0.9916667\n",
      "31 Train accuracy: 1.0 Val accuracy: 0.9583333\n",
      "32 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "33 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "34 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "35 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "36 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "37 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "38 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "39 Train accuracy: 1.0 Val accuracy: 0.98333335\n",
      "40 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "41 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "42 Train accuracy: 1.0 Val accuracy: 0.9916667\n",
      "43 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "44 Train accuracy: 1.0 Val accuracy: 0.9916667\n",
      "45 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "46 Train accuracy: 1.0 Val accuracy: 0.98333335\n",
      "47 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "48 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "49 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "50 Train accuracy: 1.0 Val accuracy: 0.9916667\n",
      "51 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "52 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "53 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "54 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "55 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "56 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "57 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "58 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "59 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "60 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "61 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "62 Train accuracy: 1.0 Val accuracy: 0.9916667\n",
      "63 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "64 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "65 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "66 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "67 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "68 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "69 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "70 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "71 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "72 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "73 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "74 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "75 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "76 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "77 Train accuracy: 1.0 Val accuracy: 0.9916667\n",
      "78 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "79 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "80 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "81 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "82 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "83 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "84 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "85 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "86 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "87 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "88 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "89 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "90 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "91 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "92 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "93 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "94 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "95 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "96 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "97 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "98 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "99 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "100 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "101 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "102 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "103 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "104 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "105 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "106 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "107 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "108 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "109 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "110 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "111 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "112 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "113 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "114 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "115 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "116 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "117 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "118 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "119 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "120 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "121 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "122 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "123 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "124 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "125 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "126 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "127 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "128 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "129 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "130 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "131 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "132 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "133 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "134 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "135 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "136 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "137 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "138 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "139 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "140 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "141 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "142 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "143 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "144 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "145 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "146 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "147 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "148 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "149 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "150 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "151 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "152 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "153 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "154 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "155 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "156 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "157 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "158 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "159 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "160 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "161 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "162 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "163 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "164 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "165 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "166 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "167 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "168 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "169 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "170 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "171 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "172 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "173 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "174 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "175 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "176 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "177 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "178 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "179 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "180 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "181 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "182 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "183 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "184 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "185 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "186 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "187 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "188 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "189 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "190 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "191 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "192 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "193 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "194 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "195 Train accuracy: 1.0 Val accuracy: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "197 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "198 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "199 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "0:00:14.532838\n"
     ]
    }
   ],
   "source": [
    "#set up logging\n",
    "logdir = log_dir(\"/Users/sdgeo/Dropbox/Der Lab/Data/IremRPPA/tf_test\", \"dnn_batch\")\n",
    "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())\n",
    "\n",
    "\n",
    "extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "config = tf.ConfigProto()\n",
    "#config.log_device_placement=True\n",
    "config.allow_soft_placement=True\n",
    "\n",
    "with tf.Session(config=config) as sess:\n",
    "    start = datetime.utcnow()\n",
    "    current_best = 0\n",
    "    init.run()\n",
    "    \n",
    "    #build a gigantic queue for all the data\n",
    "    for times in range(n_epochs * num_batches):\n",
    "            X_batch, y_batch = random_batch(train_treatment_tensor, train_treatment_labels_tensor, batch_size)\n",
    "            sess.run(enqueue, feed_dict={X_input: X_batch, y_input: y_batch})\n",
    "    sess.run([close_q])\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        for item in range(num_batches):   \n",
    "            X_item, y_item = sess.run([X_out, y_out])\n",
    "            sess.run([training_op, extra_update_ops],feed_dict={training: True, X: X_item, y: y_item})\n",
    "        acc_train = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "        \n",
    "        acc_val, acc_sum = sess.run([accuracy, accuracy_summary],feed_dict={X: test_treatment_tensor, y: test_treatment_labels_tensor})\n",
    "        file_writer.add_summary(acc_sum, epoch)\n",
    "        if (acc_val > current_best):\n",
    "            current_best = acc_val\n",
    "            saver.save(sess, \"/tmp/test/rppa_model_current_best_dropout_final.ckpt\")\n",
    "        print(epoch, \"Train accuracy:\", acc_train, \"Val accuracy:\", acc_val)\n",
    "    \n",
    "    print(datetime.utcnow() - start)   \n",
    "    \n",
    "file_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/test/rppa_model_current_best_dropout_final.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with tf.Session(config=config) as sess:\n",
    "    saver.restore(sess, \"/tmp/test/rppa_model_current_best_dropout_final.ckpt\")\n",
    "    X_new_scaled = test_treatment_tensor\n",
    "    y_raw = logits.eval(feed_dict={training: False, X: X_new_scaled})\n",
    "    y_pred = np.argmax(y_raw, axis=1)\n",
    "    \n",
    "f1_score(y_pred, test_treatment_labels_tensor, average='macro')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store the training data as a variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build the graph\n",
    "reset_graph()\n",
    "from datetime import datetime\n",
    "from functools import partial\n",
    "\n",
    "n_inputs = len(train_treatment_tensor[0])\n",
    "n_rows = len(train_treatment_tensor)\n",
    "n_rows_test = len(test_treatment_tensor)\n",
    "n_hidden1 = n_inputs\n",
    "n_hidden2 = 100\n",
    "n_hidden3 = 50\n",
    "n_outputs = 4\n",
    "\n",
    "dropout_rate = 0.5\n",
    "\n",
    "\n",
    "    \n",
    "X_init = tf.placeholder(tf.float32, shape = (n_rows, n_inputs), name=\"X_init\")\n",
    "y_init = tf.placeholder(tf.int64, shape=(n_rows), name = \"y_init\")\n",
    "    \n",
    "X_Data = tf.Variable(X_init, trainable=False, collections=[], name=\"X_Data\")\n",
    "y_Data = tf.Variable(y_init, trainable=False, collections=[], name=\"y_Data\")\n",
    "\n",
    "X_init_test = tf.placeholder(tf.float32, shape = (n_rows_test, n_inputs), name=\"X_init_test\")\n",
    "y_init_test = tf.placeholder(tf.int64, shape=(n_rows_test), name = \"y_init_test\")\n",
    "    \n",
    "X_Data_test = tf.Variable(X_init_test, trainable=False, collections=[], name=\"X_Data_test\")\n",
    "y_Data_test = tf.Variable(y_init_test, trainable=False, collections=[], name=\"y_Data_test\")\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape = (None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int64, shape=(None), name = \"y\")\n",
    "    \n",
    "training = tf.placeholder_with_default(False, shape=(), name = 'training')\n",
    "\n",
    "#he_init = tf.contrib.layers.variance_scaling_initializer()\n",
    "bn_batch_norm_layer = partial(tf.layers.batch_normalization, training=training, momentum=0.9)\n",
    "he_init = tf.contrib.layers.variance_scaling_initializer()\n",
    "\n",
    " #using tensorflow\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    X_dropout = tf.layers.dropout(X, dropout_rate, training=training)\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, name=\"hidden1\", kernel_initializer=he_init)\n",
    "    hidden1_drop = tf.layers.dropout(hidden1, dropout_rate, training=training)\n",
    "    bn1 = bn_batch_norm_layer(hidden1_drop)\n",
    "    bn1_act = tf.nn.elu(bn1)\n",
    "    \n",
    "    hidden2 = tf.layers.dense(bn1_act, n_hidden2, name=\"hidden2\", kernel_initializer=he_init)\n",
    "    hidden2_drop = tf.layers.dropout(hidden2, dropout_rate, training=training)\n",
    "    bn2 = bn_batch_norm_layer(hidden2_drop)\n",
    "    bn2_act = tf.nn.elu(bn2)\n",
    "    \n",
    "    hidden3 = tf.layers.dense(bn2_act, n_hidden3, name=\"hidden3\", kernel_initializer=he_init)\n",
    "    hidden3_drop = tf.layers.dropout(hidden3, dropout_rate, training=training)\n",
    "    bn3 = bn_batch_norm_layer(hidden3_drop)\n",
    "    bn3_act = tf.nn.elu(bn3)\n",
    "    \n",
    "    logits_before_bn = tf.layers.dense(bn3_act, n_outputs, name=\"outputs\")\n",
    "    logits = bn_batch_norm_layer(logits_before_bn)\n",
    "    \n",
    "#Calculate the loss out fo the last layer\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "    \n",
    "#Describe a way to train\n",
    "\n",
    "learning_rate = 0.01\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "    \n",
    " #Evaluate the model\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "    accuracy_summary = tf.summary.scalar('accuracy', accuracy)\n",
    " \n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train accuracy: 0.4 Val accuracy: 0.516667\n",
      "1 Train accuracy: 0.4 Val accuracy: 0.5\n",
      "2 Train accuracy: 0.4 Val accuracy: 0.533333\n",
      "3 Train accuracy: 1.0 Val accuracy: 0.575\n",
      "4 Train accuracy: 0.8 Val accuracy: 0.566667\n",
      "5 Train accuracy: 1.0 Val accuracy: 0.633333\n",
      "6 Train accuracy: 0.6 Val accuracy: 0.625\n",
      "7 Train accuracy: 0.4 Val accuracy: 0.766667\n",
      "8 Train accuracy: 1.0 Val accuracy: 0.791667\n",
      "9 Train accuracy: 0.6 Val accuracy: 0.708333\n",
      "10 Train accuracy: 1.0 Val accuracy: 0.816667\n",
      "11 Train accuracy: 1.0 Val accuracy: 0.833333\n",
      "12 Train accuracy: 1.0 Val accuracy: 0.875\n",
      "13 Train accuracy: 0.6 Val accuracy: 0.908333\n",
      "14 Train accuracy: 1.0 Val accuracy: 0.933333\n",
      "15 Train accuracy: 1.0 Val accuracy: 0.8\n",
      "16 Train accuracy: 1.0 Val accuracy: 0.858333\n",
      "17 Train accuracy: 0.8 Val accuracy: 0.858333\n",
      "18 Train accuracy: 1.0 Val accuracy: 0.841667\n",
      "19 Train accuracy: 0.8 Val accuracy: 0.858333\n",
      "20 Train accuracy: 1.0 Val accuracy: 0.9\n",
      "21 Train accuracy: 1.0 Val accuracy: 0.941667\n",
      "22 Train accuracy: 1.0 Val accuracy: 0.908333\n",
      "23 Train accuracy: 0.8 Val accuracy: 0.9\n",
      "24 Train accuracy: 1.0 Val accuracy: 0.883333\n",
      "25 Train accuracy: 1.0 Val accuracy: 0.925\n",
      "26 Train accuracy: 1.0 Val accuracy: 0.95\n",
      "27 Train accuracy: 1.0 Val accuracy: 0.975\n",
      "28 Train accuracy: 1.0 Val accuracy: 0.958333\n",
      "29 Train accuracy: 1.0 Val accuracy: 0.95\n",
      "30 Train accuracy: 1.0 Val accuracy: 0.983333\n",
      "31 Train accuracy: 1.0 Val accuracy: 0.975\n",
      "32 Train accuracy: 1.0 Val accuracy: 0.991667\n",
      "33 Train accuracy: 1.0 Val accuracy: 0.975\n",
      "34 Train accuracy: 1.0 Val accuracy: 0.966667\n",
      "35 Train accuracy: 1.0 Val accuracy: 0.966667\n",
      "36 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "37 Train accuracy: 1.0 Val accuracy: 0.983333\n",
      "38 Train accuracy: 1.0 Val accuracy: 0.991667\n",
      "39 Train accuracy: 1.0 Val accuracy: 0.983333\n",
      "40 Train accuracy: 1.0 Val accuracy: 0.975\n",
      "41 Train accuracy: 1.0 Val accuracy: 0.983333\n",
      "42 Train accuracy: 1.0 Val accuracy: 0.966667\n",
      "43 Train accuracy: 1.0 Val accuracy: 0.991667\n",
      "44 Train accuracy: 1.0 Val accuracy: 0.983333\n",
      "45 Train accuracy: 0.8 Val accuracy: 0.966667\n",
      "46 Train accuracy: 1.0 Val accuracy: 0.975\n",
      "47 Train accuracy: 1.0 Val accuracy: 0.975\n",
      "48 Train accuracy: 1.0 Val accuracy: 0.966667\n",
      "49 Train accuracy: 1.0 Val accuracy: 0.975\n",
      "50 Train accuracy: 1.0 Val accuracy: 0.966667\n",
      "51 Train accuracy: 1.0 Val accuracy: 0.991667\n",
      "52 Train accuracy: 1.0 Val accuracy: 0.975\n",
      "53 Train accuracy: 1.0 Val accuracy: 0.983333\n",
      "54 Train accuracy: 1.0 Val accuracy: 0.983333\n",
      "55 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "56 Train accuracy: 1.0 Val accuracy: 0.991667\n",
      "57 Train accuracy: 1.0 Val accuracy: 0.991667\n",
      "58 Train accuracy: 1.0 Val accuracy: 0.983333\n",
      "59 Train accuracy: 1.0 Val accuracy: 0.983333\n",
      "60 Train accuracy: 1.0 Val accuracy: 0.991667\n",
      "61 Train accuracy: 1.0 Val accuracy: 0.991667\n",
      "62 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "63 Train accuracy: 1.0 Val accuracy: 0.975\n",
      "64 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "65 Train accuracy: 1.0 Val accuracy: 0.991667\n",
      "66 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "67 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "68 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "69 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "70 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "71 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "72 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "73 Train accuracy: 1.0 Val accuracy: 0.991667\n",
      "74 Train accuracy: 1.0 Val accuracy: 0.991667\n",
      "75 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "76 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "77 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "78 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "79 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "80 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "81 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "82 Train accuracy: 1.0 Val accuracy: 0.991667\n",
      "83 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "84 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "85 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "86 Train accuracy: 1.0 Val accuracy: 0.991667\n",
      "87 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "88 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "89 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "90 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "91 Train accuracy: 1.0 Val accuracy: 0.983333\n",
      "92 Train accuracy: 1.0 Val accuracy: 0.983333\n",
      "93 Train accuracy: 1.0 Val accuracy: 0.991667\n",
      "94 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "95 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "96 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "97 Train accuracy: 1.0 Val accuracy: 0.991667\n",
      "98 Train accuracy: 1.0 Val accuracy: 0.991667\n",
      "99 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "100 Train accuracy: 1.0 Val accuracy: 0.991667\n",
      "101 Train accuracy: 1.0 Val accuracy: 0.991667\n",
      "102 Train accuracy: 1.0 Val accuracy: 0.991667\n",
      "103 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "104 Train accuracy: 1.0 Val accuracy: 0.991667\n",
      "105 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "106 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "107 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "108 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "109 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "110 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "111 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "112 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "113 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "114 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "115 Train accuracy: 1.0 Val accuracy: 0.975\n",
      "116 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "117 Train accuracy: 1.0 Val accuracy: 0.975\n",
      "118 Train accuracy: 1.0 Val accuracy: 0.991667\n",
      "119 Train accuracy: 1.0 Val accuracy: 0.991667\n",
      "120 Train accuracy: 1.0 Val accuracy: 0.983333\n",
      "121 Train accuracy: 1.0 Val accuracy: 0.991667\n",
      "122 Train accuracy: 1.0 Val accuracy: 0.991667\n",
      "123 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "124 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "125 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "126 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "127 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "128 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "129 Train accuracy: 1.0 Val accuracy: 0.991667\n",
      "130 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "131 Train accuracy: 1.0 Val accuracy: 0.991667\n",
      "132 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "133 Train accuracy: 1.0 Val accuracy: 0.991667\n",
      "134 Train accuracy: 1.0 Val accuracy: 0.991667\n",
      "135 Train accuracy: 1.0 Val accuracy: 0.983333\n",
      "136 Train accuracy: 1.0 Val accuracy: 0.991667\n",
      "137 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "138 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "139 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "140 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "141 Train accuracy: 1.0 Val accuracy: 0.991667\n",
      "142 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "143 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "144 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "145 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "146 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "147 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "148 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "149 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "150 Train accuracy: 1.0 Val accuracy: 0.991667\n",
      "151 Train accuracy: 1.0 Val accuracy: 0.991667\n",
      "152 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "153 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "154 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "155 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "156 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "157 Train accuracy: 1.0 Val accuracy: 0.991667\n",
      "158 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "159 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "160 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "161 Train accuracy: 1.0 Val accuracy: 0.991667\n",
      "162 Train accuracy: 1.0 Val accuracy: 0.991667\n",
      "163 Train accuracy: 1.0 Val accuracy: 0.991667\n",
      "164 Train accuracy: 1.0 Val accuracy: 0.983333\n",
      "165 Train accuracy: 1.0 Val accuracy: 0.991667\n",
      "166 Train accuracy: 1.0 Val accuracy: 0.991667\n",
      "167 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "168 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "169 Train accuracy: 1.0 Val accuracy: 0.991667\n",
      "170 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "171 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "172 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "173 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "174 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "175 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "176 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "177 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "178 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "179 Train accuracy: 1.0 Val accuracy: 0.991667\n",
      "180 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "181 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "182 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "183 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "184 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "185 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "186 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "187 Train accuracy: 1.0 Val accuracy: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "189 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "190 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "191 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "192 Train accuracy: 1.0 Val accuracy: 0.991667\n",
      "193 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "194 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "195 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "196 Train accuracy: 1.0 Val accuracy: 1.0\n",
      "197 Train accuracy: 1.0 Val accuracy: 0.991667\n",
      "198 Train accuracy: 1.0 Val accuracy: 0.991667\n",
      "199 Train accuracy: 1.0 Val accuracy: 0.991667\n",
      "0:00:51.360741\n"
     ]
    }
   ],
   "source": [
    "#set up logging\n",
    "logdir = log_dir(\"/Users/sdgeo/Dropbox/Der Lab/Data/IremRPPA/tf_test\", \"dnn_batch\")\n",
    "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())\n",
    "\n",
    "n_epochs = 200\n",
    "num_batches = len(train_treatment_tensor) // batch_size\n",
    "batch_size = 5\n",
    "\n",
    "extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "config = tf.ConfigProto()\n",
    "#config.log_device_placement=True\n",
    "config.allow_soft_placement=True\n",
    "\n",
    "with tf.Session(config=config) as sess:\n",
    "    start = datetime.utcnow()\n",
    "    current_best = 0\n",
    "    init.run()\n",
    "    sess.run([X_Data.initializer, y_Data.initializer], feed_dict={X_init: train_treatment_tensor, y_init: train_treatment_labels_tensor})\n",
    "    sess.run([X_Data_test.initializer, y_Data_test.initializer], feed_dict={X_init_test: test_treatment_tensor, y_init_test: test_treatment_labels_tensor})\n",
    "    X_value, y_value = sess.run([X_Data, y_Data])\n",
    "    X_value_test, y_value_test = sess.run([X_Data_test, y_Data_test])\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(n_rows // batch_size):\n",
    "            X_batch, y_batch = random_batch(X_value, y_value, batch_size)\n",
    "            sess.run([training_op, extra_update_ops],feed_dict={training: True, X: X_batch, y: y_batch})\n",
    "        acc_train = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "        \n",
    "        acc_val, acc_sum = sess.run([accuracy, accuracy_summary],feed_dict={X: X_value_test, y: y_value_test})\n",
    "        file_writer.add_summary(acc_sum, epoch)\n",
    "        if (acc_val > current_best):\n",
    "            current_best = acc_val\n",
    "            saver.save(sess, \"/tmp/test/rppa_model_current_best_dropout_final.ckpt\")\n",
    "        print(epoch, \"Train accuracy:\", acc_train, \"Val accuracy:\", acc_val)\n",
    "        \n",
    "    print(datetime.utcnow() - start)\n",
    "        \n",
    "file_writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using a Queuerunner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "class DNN_Model:\n",
    "    def __init__(self, n_epochs=200, batch_size=10, n_outputs=4, model_path=\"/tmp/models/current_model.ckpt\"):\n",
    "        self.n_epochs=n_epochs\n",
    "        self.batch_size=batch_size\n",
    "        self.n_outputs=n_outputs\n",
    "        self.model_path=model_path\n",
    "    \n",
    "    def make_and_push_instance(self, X_Data, y_Data, instance_queue, batch_size):\n",
    "        features, target = random_batch(X_Data, y_Data, batch_size)\n",
    "        enqueue_instance = instance_queue.enqueue([features, target])\n",
    "        return enqueue_instance\n",
    "    def fit(self, X_data, y_data):\n",
    "        #Build the graph\n",
    "        reset_graph()\n",
    "        n_inputs = len(X_data[0])\n",
    "        num_batches = len(X_data) // batch_size\n",
    "        n_hidden1 = n_inputs\n",
    "        n_hidden2 = 150\n",
    "        n_hidden3 = 100\n",
    "        n_hidden4 = 50\n",
    "        dropout_rate = 0.5\n",
    "\n",
    "\n",
    "        q = tf.FIFOQueue(capacity=num_batches * self.n_epochs, dtypes=[tf.float32, tf.int64], \n",
    "                 shapes=[(self.batch_size, n_inputs), (self.batch_size)], \n",
    "                        name=\"data\", shared_name=\"shared_data\")\n",
    "\n",
    "        #build the 12 functions to be run in parralel\n",
    "        add_to_queue = [make_and_push_instance(X_data, y_data, q, self.batch_size) for i in range(12)]\n",
    "        queue_runner = tf.train.QueueRunner(q, add_to_queue)\n",
    "\n",
    "        X_out, y_out = q.dequeue()\n",
    "\n",
    "        X = tf.placeholder(tf.float32, shape = (None, n_inputs), name=\"X_input\")\n",
    "        y = tf.placeholder(tf.int64, shape=(None), name = \"y_input\")\n",
    "\n",
    "        training = tf.placeholder_with_default(False, shape=(), name = 'training')\n",
    "\n",
    "        #he_init = tf.contrib.layers.variance_scaling_initializer()\n",
    "        bn_batch_norm_layer = partial(tf.layers.batch_normalization, training=training, momentum=0.9)\n",
    "        he_init = tf.contrib.layers.variance_scaling_initializer()\n",
    "\n",
    "         #using tensorflow\n",
    "        with tf.name_scope(\"dnn\"):\n",
    "            X_dropout = tf.layers.dropout(X, dropout_rate, training=training)\n",
    "            hidden1 = tf.layers.dense(X, n_hidden1, name=\"hidden1\", kernel_initializer=he_init)\n",
    "            hidden1_drop = tf.layers.dropout(hidden1, dropout_rate, training=training)\n",
    "            bn1 = bn_batch_norm_layer(hidden1_drop)\n",
    "            bn1_act = tf.nn.elu(bn1)\n",
    "\n",
    "            hidden2 = tf.layers.dense(bn1_act, n_hidden2, name=\"hidden2\", kernel_initializer=he_init)\n",
    "            hidden2_drop = tf.layers.dropout(hidden2, dropout_rate, training=training)\n",
    "            bn2 = bn_batch_norm_layer(hidden2_drop)\n",
    "            bn2_act = tf.nn.elu(bn2)\n",
    "\n",
    "            hidden3 = tf.layers.dense(bn2_act, n_hidden3, name=\"hidden3\", kernel_initializer=he_init)\n",
    "            hidden3_drop = tf.layers.dropout(hidden3, dropout_rate, training=training)\n",
    "            bn3 = bn_batch_norm_layer(hidden3_drop)\n",
    "            bn3_act = tf.nn.elu(bn3)\n",
    "            \n",
    "            hidden4 = tf.layers.dense(bn3_act, n_hidden4, name=\"hidden4\", kernel_initializer=he_init)\n",
    "            hidden4_drop = tf.layers.dropout(hidden4, dropout_rate, training=training)\n",
    "            bn4 = bn_batch_norm_layer(hidden4_drop)\n",
    "            bn4_act = tf.nn.elu(bn4)\n",
    "\n",
    "            logits_before_bn = tf.layers.dense(bn4_act, n_outputs, name=\"outputs\")\n",
    "            logits = bn_batch_norm_layer(logits_before_bn, name=\"logits\")\n",
    "        #Calculate the loss out fo the last layer\n",
    "\n",
    "        with tf.name_scope(\"loss\"):\n",
    "            xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "            loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "        #Describe a way to train\n",
    "\n",
    "        learning_rate = 0.01\n",
    "        with tf.name_scope(\"train\"):\n",
    "            optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "            training_op = optimizer.minimize(loss)\n",
    "\n",
    "         #Evaluate the model\n",
    "        with tf.name_scope(\"eval\"):\n",
    "            correct = tf.nn.in_top_k(logits, y, 1)\n",
    "            accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "            accuracy_summary = tf.summary.scalar('accuracy', accuracy)\n",
    "\n",
    "\n",
    "        init = tf.global_variables_initializer()\n",
    "        saver = tf.train.Saver()\n",
    "        #set up logging\n",
    "        extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "        #config.log_device_placement=True\n",
    "        config.allow_soft_placement=True\n",
    "        with tf.Session(config=config) as sess:\n",
    "            start = datetime.utcnow()\n",
    "            current_best = 0\n",
    "            init.run()\n",
    "\n",
    "            #build a gigantic queue for all the data\n",
    "            coord = tf.train.Coordinator()\n",
    "            enqueue_threads = queue_runner.create_threads(sess, coord=coord, start=True)\n",
    "\n",
    "            for epoch in range(n_epochs):\n",
    "                for item in range(num_batches):   \n",
    "                    X_item, y_item = sess.run([X_out, y_out])\n",
    "\n",
    "                    sess.run([training_op, extra_update_ops],feed_dict={training: True, X: X_item, y: y_item})\n",
    "                acc_train = accuracy.eval(feed_dict={X: X_item, y: y_item})\n",
    "                #print(X_item, y_item)\n",
    "                acc_val, acc_sum = sess.run([accuracy, accuracy_summary],feed_dict={X: X_data, y: y_data})\n",
    "                if (acc_val > current_best):\n",
    "                    current_best = acc_val\n",
    "                    saver.save(sess, self.model_path)\n",
    "                #print(epoch, \"Train accuracy:\", acc_train, \"Val accuracy:\", acc_val)\n",
    "\n",
    "            coord.request_stop()\n",
    "            #print(datetime.utcnow() - start)  \n",
    "    \n",
    "    def predict(self, X):\n",
    "        with tf.Session(config=tf.ConfigProto(allow_soft_placement=True)) as sess:\n",
    "            saver.restore(sess, self.model_path)\n",
    "            X_new_scaled = X\n",
    "            logits = tf.get_default_graph().get_tensor_by_name(\"dnn/logits/batchnorm/add_1:0\")\n",
    "            X_tensor = tf.get_default_graph().get_tensor_by_name(\"X_input:0\")\n",
    "            training = tf.get_default_graph().get_tensor_by_name(\"training:0\")\n",
    "            y_raw = logits.eval(feed_dict={training: False, X_tensor: X_new_scaled})\n",
    "            y_pred = np.argmax(y_raw, axis=1)\n",
    "            return(y_pred)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The function that will be run in threads\n",
    "def make_and_push_instance(X_Data, y_Data, instance_queue, batch_size):\n",
    "    features, target = random_batch(X_Data, y_Data, batch_size)\n",
    "    enqueue_instance = instance_queue.enqueue([features, target])\n",
    "    return enqueue_instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"dnn/logits/batchnorm/add_1:0\", shape=(?, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#Build the graph\n",
    "reset_graph()\n",
    "from datetime import datetime\n",
    "from functools import partial\n",
    "\n",
    "n_inputs = len(train_treatment_tensor[0])\n",
    "n_rows = len(train_treatment_tensor)\n",
    "n_epochs = 200\n",
    "batch_size = 10\n",
    "num_batches = len(train_treatment_tensor) // batch_size\n",
    "n_hidden1 = n_inputs\n",
    "n_hidden2 = 100\n",
    "n_hidden3 = 50\n",
    "n_outputs = 4\n",
    "\n",
    "dropout_rate = 0.5\n",
    "\n",
    "with tf.device(\"/gpu:0\"):\n",
    "    q = tf.FIFOQueue(capacity=num_batches * n_epochs, dtypes=[tf.float32, tf.int64], \n",
    "                     shapes=[(batch_size, n_inputs), (batch_size)], \n",
    "                            name=\"data\", shared_name=\"shared_data\")\n",
    "    #build the 12 functions to be run in parralel\n",
    "    add_to_queue = [make_and_push_instance(train_treatment_tensor, train_treatment_labels_tensor, q, batch_size) for i in range(12)]\n",
    "    queue_runner = tf.train.QueueRunner(q, add_to_queue)\n",
    "\n",
    "X_out, y_out = q.dequeue()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape = (None, n_inputs), name=\"X_input\")\n",
    "\n",
    "y = tf.placeholder(tf.int64, shape=(None), name = \"y_input\")\n",
    "\n",
    "training = tf.placeholder_with_default(False, shape=(), name = 'training')\n",
    "\n",
    "#he_init = tf.contrib.layers.variance_scaling_initializer()\n",
    "bn_batch_norm_layer = partial(tf.layers.batch_normalization, training=training, momentum=0.9)\n",
    "he_init = tf.contrib.layers.variance_scaling_initializer()\n",
    "\n",
    " #using tensorflow\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    X_dropout = tf.layers.dropout(X, dropout_rate, training=training)\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, name=\"hidden1\", kernel_initializer=he_init)\n",
    "    hidden1_drop = tf.layers.dropout(hidden1, dropout_rate, training=training)\n",
    "    bn1 = bn_batch_norm_layer(hidden1_drop)\n",
    "    bn1_act = tf.nn.elu(bn1)\n",
    "\n",
    "    hidden2 = tf.layers.dense(bn1_act, n_hidden2, name=\"hidden2\", kernel_initializer=he_init)\n",
    "    hidden2_drop = tf.layers.dropout(hidden2, dropout_rate, training=training)\n",
    "    bn2 = bn_batch_norm_layer(hidden2_drop)\n",
    "    bn2_act = tf.nn.elu(bn2)\n",
    "\n",
    "    hidden3 = tf.layers.dense(bn2_act, n_hidden3, name=\"hidden3\", kernel_initializer=he_init)\n",
    "    hidden3_drop = tf.layers.dropout(hidden3, dropout_rate, training=training)\n",
    "    bn3 = bn_batch_norm_layer(hidden3_drop)\n",
    "    bn3_act = tf.nn.elu(bn3)\n",
    "\n",
    "    logits_before_bn = tf.layers.dense(bn3_act, n_outputs, name=\"outputs\")\n",
    "    logits = bn_batch_norm_layer(logits_before_bn, name=\"logits\")\n",
    "\n",
    "print(logits)\n",
    "#Calculate the loss out fo the last layer\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "#Describe a way to train\n",
    "\n",
    "learning_rate = 0.01\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "\n",
    " #Evaluate the model\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "    accuracy_summary = tf.summary.scalar('accuracy', accuracy)\n",
    "\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train accuracy: 0.8 Val accuracy: 0.55\n",
      "1 Train accuracy: 0.8 Val accuracy: 0.7083333\n",
      "2 Train accuracy: 1.0 Val accuracy: 0.76666665\n",
      "3 Train accuracy: 1.0 Val accuracy: 0.89166665\n",
      "4 Train accuracy: 1.0 Val accuracy: 0.8333333\n",
      "5 Train accuracy: 1.0 Val accuracy: 0.8666667\n",
      "6 Train accuracy: 1.0 Val accuracy: 0.89166665\n",
      "7 Train accuracy: 1.0 Val accuracy: 0.89166665\n",
      "8 Train accuracy: 1.0 Val accuracy: 0.9166667\n",
      "9 Train accuracy: 1.0 Val accuracy: 0.90833336\n",
      "10 Train accuracy: 1.0 Val accuracy: 0.85833335\n",
      "11 Train accuracy: 1.0 Val accuracy: 0.9\n",
      "12 Train accuracy: 1.0 Val accuracy: 0.85833335\n",
      "13 Train accuracy: 1.0 Val accuracy: 0.9\n",
      "14 Train accuracy: 1.0 Val accuracy: 0.8833333\n",
      "15 Train accuracy: 1.0 Val accuracy: 0.8833333\n",
      "16 Train accuracy: 1.0 Val accuracy: 0.95\n",
      "17 Train accuracy: 1.0 Val accuracy: 0.89166665\n",
      "18 Train accuracy: 1.0 Val accuracy: 0.925\n",
      "19 Train accuracy: 1.0 Val accuracy: 0.9\n",
      "20 Train accuracy: 1.0 Val accuracy: 0.90833336\n",
      "21 Train accuracy: 1.0 Val accuracy: 0.8833333\n",
      "22 Train accuracy: 1.0 Val accuracy: 0.93333334\n",
      "23 Train accuracy: 1.0 Val accuracy: 0.9\n",
      "24 Train accuracy: 1.0 Val accuracy: 0.8833333\n",
      "25 Train accuracy: 1.0 Val accuracy: 0.9166667\n",
      "26 Train accuracy: 1.0 Val accuracy: 0.89166665\n",
      "27 Train accuracy: 1.0 Val accuracy: 0.9166667\n",
      "28 Train accuracy: 1.0 Val accuracy: 0.925\n",
      "29 Train accuracy: 1.0 Val accuracy: 0.89166665\n",
      "30 Train accuracy: 1.0 Val accuracy: 0.9\n",
      "31 Train accuracy: 1.0 Val accuracy: 0.9\n",
      "32 Train accuracy: 1.0 Val accuracy: 0.8833333\n",
      "33 Train accuracy: 1.0 Val accuracy: 0.8833333\n",
      "34 Train accuracy: 1.0 Val accuracy: 0.8833333\n",
      "35 Train accuracy: 1.0 Val accuracy: 0.9\n",
      "36 Train accuracy: 1.0 Val accuracy: 0.9\n",
      "37 Train accuracy: 1.0 Val accuracy: 0.89166665\n",
      "38 Train accuracy: 1.0 Val accuracy: 0.925\n",
      "39 Train accuracy: 1.0 Val accuracy: 0.90833336\n",
      "40 Train accuracy: 1.0 Val accuracy: 0.925\n",
      "41 Train accuracy: 1.0 Val accuracy: 0.9\n",
      "42 Train accuracy: 1.0 Val accuracy: 0.90833336\n",
      "43 Train accuracy: 1.0 Val accuracy: 0.9\n",
      "44 Train accuracy: 1.0 Val accuracy: 0.89166665\n",
      "45 Train accuracy: 1.0 Val accuracy: 0.9\n",
      "46 Train accuracy: 1.0 Val accuracy: 0.90833336\n",
      "47 Train accuracy: 1.0 Val accuracy: 0.93333334\n",
      "48 Train accuracy: 1.0 Val accuracy: 0.9\n",
      "49 Train accuracy: 1.0 Val accuracy: 0.90833336\n",
      "50 Train accuracy: 1.0 Val accuracy: 0.95\n",
      "51 Train accuracy: 1.0 Val accuracy: 0.9166667\n",
      "52 Train accuracy: 1.0 Val accuracy: 0.9\n",
      "53 Train accuracy: 1.0 Val accuracy: 0.90833336\n",
      "54 Train accuracy: 1.0 Val accuracy: 0.9166667\n",
      "55 Train accuracy: 1.0 Val accuracy: 0.90833336\n",
      "56 Train accuracy: 1.0 Val accuracy: 0.90833336\n",
      "57 Train accuracy: 1.0 Val accuracy: 0.90833336\n",
      "58 Train accuracy: 1.0 Val accuracy: 0.89166665\n",
      "59 Train accuracy: 1.0 Val accuracy: 0.96666664\n",
      "60 Train accuracy: 1.0 Val accuracy: 0.89166665\n",
      "61 Train accuracy: 1.0 Val accuracy: 0.90833336\n",
      "62 Train accuracy: 1.0 Val accuracy: 0.9166667\n",
      "63 Train accuracy: 1.0 Val accuracy: 0.9\n",
      "64 Train accuracy: 1.0 Val accuracy: 0.9166667\n",
      "65 Train accuracy: 1.0 Val accuracy: 0.8666667\n",
      "66 Train accuracy: 1.0 Val accuracy: 0.925\n",
      "67 Train accuracy: 1.0 Val accuracy: 0.90833336\n",
      "68 Train accuracy: 1.0 Val accuracy: 0.89166665\n",
      "69 Train accuracy: 1.0 Val accuracy: 0.925\n",
      "70 Train accuracy: 1.0 Val accuracy: 0.89166665\n",
      "71 Train accuracy: 1.0 Val accuracy: 0.8666667\n",
      "72 Train accuracy: 1.0 Val accuracy: 0.9\n",
      "73 Train accuracy: 1.0 Val accuracy: 0.9166667\n",
      "74 Train accuracy: 1.0 Val accuracy: 0.8833333\n",
      "75 Train accuracy: 1.0 Val accuracy: 0.89166665\n",
      "76 Train accuracy: 1.0 Val accuracy: 0.94166666\n",
      "77 Train accuracy: 1.0 Val accuracy: 0.925\n",
      "78 Train accuracy: 1.0 Val accuracy: 0.90833336\n",
      "79 Train accuracy: 1.0 Val accuracy: 0.89166665\n",
      "80 Train accuracy: 1.0 Val accuracy: 0.90833336\n",
      "81 Train accuracy: 1.0 Val accuracy: 0.94166666\n",
      "82 Train accuracy: 1.0 Val accuracy: 0.9166667\n",
      "83 Train accuracy: 1.0 Val accuracy: 0.9\n",
      "84 Train accuracy: 1.0 Val accuracy: 0.90833336\n",
      "85 Train accuracy: 1.0 Val accuracy: 0.93333334\n",
      "86 Train accuracy: 1.0 Val accuracy: 0.96666664\n",
      "87 Train accuracy: 1.0 Val accuracy: 0.93333334\n",
      "88 Train accuracy: 1.0 Val accuracy: 0.93333334\n",
      "89 Train accuracy: 1.0 Val accuracy: 0.90833336\n",
      "90 Train accuracy: 1.0 Val accuracy: 0.9166667\n",
      "91 Train accuracy: 1.0 Val accuracy: 0.9\n",
      "92 Train accuracy: 1.0 Val accuracy: 0.9166667\n",
      "93 Train accuracy: 1.0 Val accuracy: 0.93333334\n",
      "94 Train accuracy: 1.0 Val accuracy: 0.9166667\n",
      "95 Train accuracy: 1.0 Val accuracy: 0.94166666\n",
      "96 Train accuracy: 1.0 Val accuracy: 0.89166665\n",
      "97 Train accuracy: 1.0 Val accuracy: 0.925\n",
      "98 Train accuracy: 1.0 Val accuracy: 0.89166665\n",
      "99 Train accuracy: 1.0 Val accuracy: 0.9166667\n",
      "100 Train accuracy: 1.0 Val accuracy: 0.8666667\n",
      "101 Train accuracy: 1.0 Val accuracy: 0.84166664\n",
      "102 Train accuracy: 1.0 Val accuracy: 0.89166665\n",
      "103 Train accuracy: 1.0 Val accuracy: 0.94166666\n",
      "104 Train accuracy: 1.0 Val accuracy: 0.925\n",
      "105 Train accuracy: 1.0 Val accuracy: 0.95\n",
      "106 Train accuracy: 1.0 Val accuracy: 0.93333334\n",
      "107 Train accuracy: 1.0 Val accuracy: 0.93333334\n",
      "108 Train accuracy: 1.0 Val accuracy: 0.93333334\n",
      "109 Train accuracy: 1.0 Val accuracy: 0.925\n",
      "110 Train accuracy: 1.0 Val accuracy: 0.90833336\n",
      "111 Train accuracy: 1.0 Val accuracy: 0.9\n",
      "112 Train accuracy: 1.0 Val accuracy: 0.9\n",
      "113 Train accuracy: 1.0 Val accuracy: 0.9\n",
      "114 Train accuracy: 1.0 Val accuracy: 0.875\n",
      "115 Train accuracy: 1.0 Val accuracy: 0.9\n",
      "116 Train accuracy: 1.0 Val accuracy: 0.9\n",
      "117 Train accuracy: 1.0 Val accuracy: 0.8833333\n",
      "118 Train accuracy: 1.0 Val accuracy: 0.89166665\n",
      "119 Train accuracy: 1.0 Val accuracy: 0.8833333\n",
      "120 Train accuracy: 1.0 Val accuracy: 0.89166665\n",
      "121 Train accuracy: 1.0 Val accuracy: 0.90833336\n",
      "122 Train accuracy: 1.0 Val accuracy: 0.9\n",
      "123 Train accuracy: 1.0 Val accuracy: 0.9166667\n",
      "124 Train accuracy: 1.0 Val accuracy: 0.90833336\n",
      "125 Train accuracy: 1.0 Val accuracy: 0.90833336\n",
      "126 Train accuracy: 1.0 Val accuracy: 0.925\n",
      "127 Train accuracy: 1.0 Val accuracy: 0.90833336\n",
      "128 Train accuracy: 1.0 Val accuracy: 0.925\n",
      "129 Train accuracy: 1.0 Val accuracy: 0.90833336\n",
      "130 Train accuracy: 1.0 Val accuracy: 0.90833336\n",
      "131 Train accuracy: 1.0 Val accuracy: 0.90833336\n",
      "132 Train accuracy: 1.0 Val accuracy: 0.925\n",
      "133 Train accuracy: 1.0 Val accuracy: 0.875\n",
      "134 Train accuracy: 1.0 Val accuracy: 0.875\n",
      "135 Train accuracy: 1.0 Val accuracy: 0.89166665\n",
      "136 Train accuracy: 1.0 Val accuracy: 0.875\n",
      "137 Train accuracy: 1.0 Val accuracy: 0.9\n",
      "138 Train accuracy: 1.0 Val accuracy: 0.9\n",
      "139 Train accuracy: 1.0 Val accuracy: 0.8833333\n",
      "140 Train accuracy: 1.0 Val accuracy: 0.90833336\n",
      "141 Train accuracy: 1.0 Val accuracy: 0.875\n",
      "142 Train accuracy: 1.0 Val accuracy: 0.9\n",
      "143 Train accuracy: 1.0 Val accuracy: 0.9166667\n",
      "144 Train accuracy: 1.0 Val accuracy: 0.9\n",
      "145 Train accuracy: 1.0 Val accuracy: 0.90833336\n",
      "146 Train accuracy: 1.0 Val accuracy: 0.89166665\n",
      "147 Train accuracy: 1.0 Val accuracy: 0.8833333\n",
      "148 Train accuracy: 1.0 Val accuracy: 0.89166665\n",
      "149 Train accuracy: 1.0 Val accuracy: 0.89166665\n",
      "150 Train accuracy: 1.0 Val accuracy: 0.90833336\n",
      "151 Train accuracy: 1.0 Val accuracy: 0.89166665\n",
      "152 Train accuracy: 1.0 Val accuracy: 0.875\n",
      "153 Train accuracy: 1.0 Val accuracy: 0.8833333\n",
      "154 Train accuracy: 1.0 Val accuracy: 0.90833336\n",
      "155 Train accuracy: 1.0 Val accuracy: 0.9583333\n",
      "156 Train accuracy: 1.0 Val accuracy: 0.9166667\n",
      "157 Train accuracy: 1.0 Val accuracy: 0.875\n",
      "158 Train accuracy: 1.0 Val accuracy: 0.925\n",
      "159 Train accuracy: 1.0 Val accuracy: 0.9\n",
      "160 Train accuracy: 1.0 Val accuracy: 0.9166667\n",
      "161 Train accuracy: 1.0 Val accuracy: 0.8833333\n",
      "162 Train accuracy: 1.0 Val accuracy: 0.875\n",
      "163 Train accuracy: 1.0 Val accuracy: 0.9\n",
      "164 Train accuracy: 1.0 Val accuracy: 0.9166667\n",
      "165 Train accuracy: 1.0 Val accuracy: 0.925\n",
      "166 Train accuracy: 1.0 Val accuracy: 0.90833336\n",
      "167 Train accuracy: 1.0 Val accuracy: 0.9\n",
      "168 Train accuracy: 1.0 Val accuracy: 0.89166665\n",
      "169 Train accuracy: 1.0 Val accuracy: 0.89166665\n",
      "170 Train accuracy: 1.0 Val accuracy: 0.93333334\n",
      "171 Train accuracy: 1.0 Val accuracy: 0.96666664\n",
      "172 Train accuracy: 1.0 Val accuracy: 0.925\n",
      "173 Train accuracy: 1.0 Val accuracy: 0.925\n",
      "174 Train accuracy: 1.0 Val accuracy: 0.9166667\n",
      "175 Train accuracy: 1.0 Val accuracy: 0.9166667\n",
      "176 Train accuracy: 1.0 Val accuracy: 0.8833333\n",
      "177 Train accuracy: 1.0 Val accuracy: 0.85833335\n",
      "178 Train accuracy: 1.0 Val accuracy: 0.8833333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179 Train accuracy: 1.0 Val accuracy: 0.90833336\n",
      "180 Train accuracy: 1.0 Val accuracy: 0.93333334\n",
      "181 Train accuracy: 1.0 Val accuracy: 0.93333334\n",
      "182 Train accuracy: 1.0 Val accuracy: 0.89166665\n",
      "183 Train accuracy: 1.0 Val accuracy: 0.925\n",
      "184 Train accuracy: 1.0 Val accuracy: 0.95\n",
      "185 Train accuracy: 1.0 Val accuracy: 0.90833336\n",
      "186 Train accuracy: 1.0 Val accuracy: 0.9\n",
      "187 Train accuracy: 1.0 Val accuracy: 0.94166666\n",
      "188 Train accuracy: 1.0 Val accuracy: 0.95\n",
      "189 Train accuracy: 1.0 Val accuracy: 0.9166667\n",
      "190 Train accuracy: 1.0 Val accuracy: 0.94166666\n",
      "191 Train accuracy: 1.0 Val accuracy: 0.9\n",
      "192 Train accuracy: 1.0 Val accuracy: 0.89166665\n",
      "193 Train accuracy: 1.0 Val accuracy: 0.9\n",
      "194 Train accuracy: 1.0 Val accuracy: 0.90833336\n",
      "195 Train accuracy: 1.0 Val accuracy: 0.89166665\n",
      "196 Train accuracy: 1.0 Val accuracy: 0.90833336\n",
      "197 Train accuracy: 1.0 Val accuracy: 0.925\n",
      "198 Train accuracy: 1.0 Val accuracy: 0.93333334\n",
      "199 Train accuracy: 1.0 Val accuracy: 0.94166666\n",
      "0:00:14.643923\n"
     ]
    }
   ],
   "source": [
    "#set up logging\n",
    "logdir = log_dir(\"/Users/sdgeo/Dropbox/Der Lab/Data/IremRPPA/tf_test\", \"dnn_out\")\n",
    "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())\n",
    "\n",
    "\n",
    "extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "config = tf.ConfigProto(device_count = {'GPU': 0})\n",
    "#config.log_device_placement=True\n",
    "config.allow_soft_placement=True\n",
    "\n",
    "\n",
    "with tf.Session(config=config) as sess:\n",
    "    start = datetime.utcnow()\n",
    "    current_best = 0\n",
    "    init.run()\n",
    "    \n",
    "    #build a gigantic queue for all the data\n",
    "    coord = tf.train.Coordinator()\n",
    "    enqueue_threads = queue_runner.create_threads(sess, coord=coord, start=True)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        for item in range(num_batches):   \n",
    "            X_item, y_item = sess.run([X_out, y_out])\n",
    "\n",
    "            sess.run([training_op, extra_update_ops],feed_dict={training: True, X: X_item, y: y_item})\n",
    "        acc_train = accuracy.eval(feed_dict={X: X_item, y: y_item})\n",
    "        #print(X_item, y_item)\n",
    "        acc_val, acc_sum = sess.run([accuracy, accuracy_summary],feed_dict={X: test_treatment_tensor, y: test_treatment_labels_tensor})\n",
    "        file_writer.add_summary(acc_sum, epoch)\n",
    "        if (acc_val > current_best):\n",
    "            current_best = acc_val\n",
    "            saver.save(sess, \"/tmp/test/rppa_model_current_best_dropout_final.ckpt\")\n",
    "        print(epoch, \"Train accuracy:\", acc_train, \"Val accuracy:\", acc_val)\n",
    "    \n",
    "    coord.request_stop()\n",
    "    print(datetime.utcnow() - start)   \n",
    "    \n",
    "file_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster_test.ipynb\n",
      "desktop.ini\n",
      "env\n",
      "Figures\n",
      "imputed_csv_sam.csv\n",
      "models\n",
      "Petricoin lab analyses\n",
      "r_scripts\n",
      "raw_data\n",
      "RPPA_DNN.ipynb\n",
      "RPPA_Figures.ipynb\n",
      "RPPA_Models.ipynb\n",
      "RPPA_Models_Cell_Line.ipynb\n",
      "tensorflow_models\n",
      "tf_logs\n",
      "tf_test\n",
      "Utilities\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./tf_logs/dnn_out-run-20180430151656/dnn_model.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9230387099239559"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DNN_Model()\n",
    "model.fit(train_treatment_tensor, train_treatment_labels_tensorf)\n",
    "y_pred = model.predict(test_treatment_tensor)\n",
    "f1_score(y_pred, test_treatment_labels_tensor, average='macro') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/models/tf_logs_final/dnn_out-run-20180427200132/dnn_model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from /tmp/models/tf_logs_final/dnn_out-run-20180427200150/dnn_model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from /tmp/models/tf_logs_final/dnn_out-run-20180427200211/dnn_model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from /tmp/models/tf_logs_final/dnn_out-run-20180427200231/dnn_model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from /tmp/models/tf_logs_final/dnn_out-run-20180427200251/dnn_model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from /tmp/models/tf_logs_final/dnn_out-run-20180427200309/dnn_model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from /tmp/models/tf_logs_final/dnn_out-run-20180427200327/dnn_model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from /tmp/models/tf_logs_final/dnn_out-run-20180427200344/dnn_model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from /tmp/models/tf_logs_final/dnn_out-run-20180427200402/dnn_model.ckpt\n",
      "INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.CancelledError'>, Enqueue operation was cancelled\n",
      "\t [[Node: data_enqueue_5 = QueueEnqueueV2[Tcomponents=[DT_FLOAT, DT_INT64], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](data, data_enqueue_5/component_0, data_enqueue_5/component_1)]]\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "Failed to rename: /tmp/models/tf_logs_final/dnn_out-run-20180427200420/dnn_model.ckpt.index.tempstate3409807438837728086 to: /tmp/models/tf_logs_final/dnn_out-run-20180427200420/dnn_model.ckpt.index : Access is denied.\r\n; Input/output error\n\t [[Node: save/SaveV2 = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/SaveV2/tensor_names, save/SaveV2/shape_and_slices, batch_normalization/beta, batch_normalization/beta/Adam, batch_normalization/beta/Adam_1, batch_normalization/gamma, batch_normalization/gamma/Adam, batch_normalization/gamma/Adam_1, batch_normalization/moving_mean, batch_normalization/moving_variance, batch_normalization_1/beta, batch_normalization_1/beta/Adam, batch_normalization_1/beta/Adam_1, batch_normalization_1/gamma, batch_normalization_1/gamma/Adam, batch_normalization_1/gamma/Adam_1, batch_normalization_1/moving_mean, batch_normalization_1/moving_variance, batch_normalization_2/beta, batch_normalization_2/beta/Adam, batch_normalization_2/beta/Adam_1, batch_normalization_2/gamma, batch_normalization_2/gamma/Adam, batch_normalization_2/gamma/Adam_1, batch_normalization_2/moving_mean, batch_normalization_2/moving_variance, batch_normalization_3/beta, batch_normalization_3/beta/Adam, batch_normalization_3/beta/Adam_1, batch_normalization_3/gamma, batch_normalization_3/gamma/Adam, batch_normalization_3/gamma/Adam_1, batch_normalization_3/moving_mean, batch_normalization_3/moving_variance, hidden1/bias, hidden1/bias/Adam, hidden1/bias/Adam_1, hidden1/kernel, hidden1/kernel/Adam, hidden1/kernel/Adam_1, hidden2/bias, hidden2/bias/Adam, hidden2/bias/Adam_1, hidden2/kernel, hidden2/kernel/Adam, hidden2/kernel/Adam_1, hidden3/bias, hidden3/bias/Adam, hidden3/bias/Adam_1, hidden3/kernel, hidden3/kernel/Adam, hidden3/kernel/Adam_1, hidden4/bias, hidden4/bias/Adam, hidden4/bias/Adam_1, hidden4/kernel, hidden4/kernel/Adam, hidden4/kernel/Adam_1, logits/beta, logits/beta/Adam, logits/beta/Adam_1, logits/gamma, logits/gamma/Adam, logits/gamma/Adam_1, logits/moving_mean, logits/moving_variance, outputs/bias, outputs/bias/Adam, outputs/bias/Adam_1, outputs/kernel, outputs/kernel/Adam, outputs/kernel/Adam_1, train/beta1_power, train/beta2_power)]]\n\nCaused by op 'save/SaveV2', defined at:\n  File \"C:\\Users\\sdgeo\\AppData\\Local\\Programs\\Python\\Python36\\Lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\sdgeo\\AppData\\Local\\Programs\\Python\\Python36\\Lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"c:\\users\\sdgeo\\dropbox\\derlab~1\\data\\iremrppa\\env\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"c:\\users\\sdgeo\\dropbox\\derlab~1\\data\\iremrppa\\env\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"c:\\users\\sdgeo\\dropbox\\derlab~1\\data\\iremrppa\\env\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"c:\\users\\sdgeo\\dropbox\\derlab~1\\data\\iremrppa\\env\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 112, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\sdgeo\\AppData\\Local\\Programs\\Python\\Python36\\Lib\\asyncio\\base_events.py\", line 421, in run_forever\n    self._run_once()\n  File \"C:\\Users\\sdgeo\\AppData\\Local\\Programs\\Python\\Python36\\Lib\\asyncio\\base_events.py\", line 1426, in _run_once\n    handle._run()\n  File \"C:\\Users\\sdgeo\\AppData\\Local\\Programs\\Python\\Python36\\Lib\\asyncio\\events.py\", line 127, in _run\n    self._callback(*self._args)\n  File \"c:\\users\\sdgeo\\dropbox\\derlab~1\\data\\iremrppa\\env\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 102, in _handle_events\n    handler_func(fileobj, events)\n  File \"c:\\users\\sdgeo\\dropbox\\derlab~1\\data\\iremrppa\\env\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"c:\\users\\sdgeo\\dropbox\\derlab~1\\data\\iremrppa\\env\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"c:\\users\\sdgeo\\dropbox\\derlab~1\\data\\iremrppa\\env\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"c:\\users\\sdgeo\\dropbox\\derlab~1\\data\\iremrppa\\env\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"c:\\users\\sdgeo\\dropbox\\derlab~1\\data\\iremrppa\\env\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"c:\\users\\sdgeo\\dropbox\\derlab~1\\data\\iremrppa\\env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"c:\\users\\sdgeo\\dropbox\\derlab~1\\data\\iremrppa\\env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"c:\\users\\sdgeo\\dropbox\\derlab~1\\data\\iremrppa\\env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"c:\\users\\sdgeo\\dropbox\\derlab~1\\data\\iremrppa\\env\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"c:\\users\\sdgeo\\dropbox\\derlab~1\\data\\iremrppa\\env\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"c:\\users\\sdgeo\\dropbox\\derlab~1\\data\\iremrppa\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"c:\\users\\sdgeo\\dropbox\\derlab~1\\data\\iremrppa\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"c:\\users\\sdgeo\\dropbox\\derlab~1\\data\\iremrppa\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-5-0d97ea1da21e>\", line 3, in <module>\n    scores = cross_val_score_dnn(model, train_treatment_tensor, train_treatment_labels_tensor)\n  File \"C:\\Users\\sdgeo\\Dropbox\\Der Lab\\Data\\IremRPPA\\Utilities\\models.py\", line 167, in cross_val_score_dnn\n    model.fit(X_train_folds, y_train_folds)\n  File \"C:\\Users\\sdgeo\\Dropbox\\Der Lab\\Data\\IremRPPA\\Utilities\\models.py\", line 115, in fit\n    saver = tf.train.Saver()\n  File \"c:\\users\\sdgeo\\dropbox\\derlab~1\\data\\iremrppa\\env\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1311, in __init__\n    self.build()\n  File \"c:\\users\\sdgeo\\dropbox\\derlab~1\\data\\iremrppa\\env\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1320, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"c:\\users\\sdgeo\\dropbox\\derlab~1\\data\\iremrppa\\env\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1357, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"c:\\users\\sdgeo\\dropbox\\derlab~1\\data\\iremrppa\\env\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 806, in _build_internal\n    save_tensor = self._AddSaveOps(filename_tensor, saveables)\n  File \"c:\\users\\sdgeo\\dropbox\\derlab~1\\data\\iremrppa\\env\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 326, in _AddSaveOps\n    save = self.save_op(filename_tensor, saveables)\n  File \"c:\\users\\sdgeo\\dropbox\\derlab~1\\data\\iremrppa\\env\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 242, in save_op\n    tensors)\n  File \"c:\\users\\sdgeo\\dropbox\\derlab~1\\data\\iremrppa\\env\\lib\\site-packages\\tensorflow\\python\\ops\\gen_io_ops.py\", line 1793, in save_v2\n    shape_and_slices=shape_and_slices, tensors=tensors, name=name)\n  File \"c:\\users\\sdgeo\\dropbox\\derlab~1\\data\\iremrppa\\env\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"c:\\users\\sdgeo\\dropbox\\derlab~1\\data\\iremrppa\\env\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3290, in create_op\n    op_def=op_def)\n  File \"c:\\users\\sdgeo\\dropbox\\derlab~1\\data\\iremrppa\\env\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1654, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nUnknownError (see above for traceback): Failed to rename: /tmp/models/tf_logs_final/dnn_out-run-20180427200420/dnn_model.ckpt.index.tempstate3409807438837728086 to: /tmp/models/tf_logs_final/dnn_out-run-20180427200420/dnn_model.ckpt.index : Access is denied.\r\n; Input/output error\n\t [[Node: save/SaveV2 = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/SaveV2/tensor_names, save/SaveV2/shape_and_slices, batch_normalization/beta, batch_normalization/beta/Adam, batch_normalization/beta/Adam_1, batch_normalization/gamma, batch_normalization/gamma/Adam, batch_normalization/gamma/Adam_1, batch_normalization/moving_mean, batch_normalization/moving_variance, batch_normalization_1/beta, batch_normalization_1/beta/Adam, batch_normalization_1/beta/Adam_1, batch_normalization_1/gamma, batch_normalization_1/gamma/Adam, batch_normalization_1/gamma/Adam_1, batch_normalization_1/moving_mean, batch_normalization_1/moving_variance, batch_normalization_2/beta, batch_normalization_2/beta/Adam, batch_normalization_2/beta/Adam_1, batch_normalization_2/gamma, batch_normalization_2/gamma/Adam, batch_normalization_2/gamma/Adam_1, batch_normalization_2/moving_mean, batch_normalization_2/moving_variance, batch_normalization_3/beta, batch_normalization_3/beta/Adam, batch_normalization_3/beta/Adam_1, batch_normalization_3/gamma, batch_normalization_3/gamma/Adam, batch_normalization_3/gamma/Adam_1, batch_normalization_3/moving_mean, batch_normalization_3/moving_variance, hidden1/bias, hidden1/bias/Adam, hidden1/bias/Adam_1, hidden1/kernel, hidden1/kernel/Adam, hidden1/kernel/Adam_1, hidden2/bias, hidden2/bias/Adam, hidden2/bias/Adam_1, hidden2/kernel, hidden2/kernel/Adam, hidden2/kernel/Adam_1, hidden3/bias, hidden3/bias/Adam, hidden3/bias/Adam_1, hidden3/kernel, hidden3/kernel/Adam, hidden3/kernel/Adam_1, hidden4/bias, hidden4/bias/Adam, hidden4/bias/Adam_1, hidden4/kernel, hidden4/kernel/Adam, hidden4/kernel/Adam_1, logits/beta, logits/beta/Adam, logits/beta/Adam_1, logits/gamma, logits/gamma/Adam, logits/gamma/Adam_1, logits/moving_mean, logits/moving_variance, outputs/bias, outputs/bias/Adam, outputs/bias/Adam_1, outputs/kernel, outputs/kernel/Adam, outputs/kernel/Adam_1, train/beta1_power, train/beta2_power)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\sdgeo\\dropbox\\derlab~1\\data\\iremrppa\\env\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1327\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1328\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sdgeo\\dropbox\\derlab~1\\data\\iremrppa\\env\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1311\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1312\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1313\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sdgeo\\dropbox\\derlab~1\\data\\iremrppa\\env\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1419\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1420\u001b[1;33m             status, run_metadata)\n\u001b[0m\u001b[0;32m   1421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sdgeo\\dropbox\\derlab~1\\data\\iremrppa\\env\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[0;32m    515\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 516\u001b[1;33m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[0;32m    517\u001b[0m     \u001b[1;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnknownError\u001b[0m: Failed to rename: /tmp/models/tf_logs_final/dnn_out-run-20180427200420/dnn_model.ckpt.index.tempstate3409807438837728086 to: /tmp/models/tf_logs_final/dnn_out-run-20180427200420/dnn_model.ckpt.index : Access is denied.\r\n; Input/output error\n\t [[Node: save/SaveV2 = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/SaveV2/tensor_names, save/SaveV2/shape_and_slices, batch_normalization/beta, batch_normalization/beta/Adam, batch_normalization/beta/Adam_1, batch_normalization/gamma, batch_normalization/gamma/Adam, batch_normalization/gamma/Adam_1, batch_normalization/moving_mean, batch_normalization/moving_variance, batch_normalization_1/beta, batch_normalization_1/beta/Adam, batch_normalization_1/beta/Adam_1, batch_normalization_1/gamma, batch_normalization_1/gamma/Adam, batch_normalization_1/gamma/Adam_1, batch_normalization_1/moving_mean, batch_normalization_1/moving_variance, batch_normalization_2/beta, batch_normalization_2/beta/Adam, batch_normalization_2/beta/Adam_1, batch_normalization_2/gamma, batch_normalization_2/gamma/Adam, batch_normalization_2/gamma/Adam_1, batch_normalization_2/moving_mean, batch_normalization_2/moving_variance, batch_normalization_3/beta, batch_normalization_3/beta/Adam, batch_normalization_3/beta/Adam_1, batch_normalization_3/gamma, batch_normalization_3/gamma/Adam, batch_normalization_3/gamma/Adam_1, batch_normalization_3/moving_mean, batch_normalization_3/moving_variance, hidden1/bias, hidden1/bias/Adam, hidden1/bias/Adam_1, hidden1/kernel, hidden1/kernel/Adam, hidden1/kernel/Adam_1, hidden2/bias, hidden2/bias/Adam, hidden2/bias/Adam_1, hidden2/kernel, hidden2/kernel/Adam, hidden2/kernel/Adam_1, hidden3/bias, hidden3/bias/Adam, hidden3/bias/Adam_1, hidden3/kernel, hidden3/kernel/Adam, hidden3/kernel/Adam_1, hidden4/bias, hidden4/bias/Adam, hidden4/bias/Adam_1, hidden4/kernel, hidden4/kernel/Adam, hidden4/kernel/Adam_1, logits/beta, logits/beta/Adam, logits/beta/Adam_1, logits/gamma, logits/gamma/Adam, logits/gamma/Adam_1, logits/moving_mean, logits/moving_variance, outputs/bias, outputs/bias/Adam, outputs/bias/Adam_1, outputs/kernel, outputs/kernel/Adam, outputs/kernel/Adam_1, train/beta1_power, train/beta2_power)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-0d97ea1da21e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDNN_Model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"/tmp/models/tf_logs_final\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_score_dnn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_treatment_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_treatment_labels_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Dropbox\\Der Lab\\Data\\IremRPPA\\Utilities\\models.py\u001b[0m in \u001b[0;36mcross_val_score_dnn\u001b[1;34m(model, X_data, y_data, cv)\u001b[0m\n\u001b[0;32m    165\u001b[0m         \u001b[0my_test_folds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 167\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_folds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_folds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    168\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_folds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m         \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test_folds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'macro'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Dropbox\\Der Lab\\Data\\IremRPPA\\Utilities\\models.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X_data, y_data)\u001b[0m\n\u001b[0;32m    139\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0macc_val\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mcurrent_best\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m                     \u001b[0mcurrent_best\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0macc_val\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m                     \u001b[0msaver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_path\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m             \u001b[0mcoord\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest_stop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sdgeo\\dropbox\\derlab~1\\data\\iremrppa\\env\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, sess, save_path, global_step, latest_filename, meta_graph_suffix, write_meta_graph, write_state, strip_default_attrs)\u001b[0m\n\u001b[0;32m   1674\u001b[0m           model_checkpoint_path = sess.run(\n\u001b[0;32m   1675\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaver_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_tensor_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1676\u001b[1;33m               {self.saver_def.filename_tensor_name: checkpoint_file})\n\u001b[0m\u001b[0;32m   1677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1678\u001b[0m         \u001b[0mmodel_checkpoint_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_checkpoint_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sdgeo\\dropbox\\derlab~1\\data\\iremrppa\\env\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    903\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 905\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    906\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sdgeo\\dropbox\\derlab~1\\data\\iremrppa\\env\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1138\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1139\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1140\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1141\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1142\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sdgeo\\dropbox\\derlab~1\\data\\iremrppa\\env\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1319\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1320\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1321\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1322\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1323\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sdgeo\\dropbox\\derlab~1\\data\\iremrppa\\env\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1338\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1339\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1340\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1341\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1342\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnknownError\u001b[0m: Failed to rename: /tmp/models/tf_logs_final/dnn_out-run-20180427200420/dnn_model.ckpt.index.tempstate3409807438837728086 to: /tmp/models/tf_logs_final/dnn_out-run-20180427200420/dnn_model.ckpt.index : Access is denied.\r\n; Input/output error\n\t [[Node: save/SaveV2 = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/SaveV2/tensor_names, save/SaveV2/shape_and_slices, batch_normalization/beta, batch_normalization/beta/Adam, batch_normalization/beta/Adam_1, batch_normalization/gamma, batch_normalization/gamma/Adam, batch_normalization/gamma/Adam_1, batch_normalization/moving_mean, batch_normalization/moving_variance, batch_normalization_1/beta, batch_normalization_1/beta/Adam, batch_normalization_1/beta/Adam_1, batch_normalization_1/gamma, batch_normalization_1/gamma/Adam, batch_normalization_1/gamma/Adam_1, batch_normalization_1/moving_mean, batch_normalization_1/moving_variance, batch_normalization_2/beta, batch_normalization_2/beta/Adam, batch_normalization_2/beta/Adam_1, batch_normalization_2/gamma, batch_normalization_2/gamma/Adam, batch_normalization_2/gamma/Adam_1, batch_normalization_2/moving_mean, batch_normalization_2/moving_variance, batch_normalization_3/beta, batch_normalization_3/beta/Adam, batch_normalization_3/beta/Adam_1, batch_normalization_3/gamma, batch_normalization_3/gamma/Adam, batch_normalization_3/gamma/Adam_1, batch_normalization_3/moving_mean, batch_normalization_3/moving_variance, hidden1/bias, hidden1/bias/Adam, hidden1/bias/Adam_1, hidden1/kernel, hidden1/kernel/Adam, hidden1/kernel/Adam_1, hidden2/bias, hidden2/bias/Adam, hidden2/bias/Adam_1, hidden2/kernel, hidden2/kernel/Adam, hidden2/kernel/Adam_1, hidden3/bias, hidden3/bias/Adam, hidden3/bias/Adam_1, hidden3/kernel, hidden3/kernel/Adam, hidden3/kernel/Adam_1, hidden4/bias, hidden4/bias/Adam, hidden4/bias/Adam_1, hidden4/kernel, hidden4/kernel/Adam, hidden4/kernel/Adam_1, logits/beta, logits/beta/Adam, logits/beta/Adam_1, logits/gamma, logits/gamma/Adam, logits/gamma/Adam_1, logits/moving_mean, logits/moving_variance, outputs/bias, outputs/bias/Adam, outputs/bias/Adam_1, outputs/kernel, outputs/kernel/Adam, outputs/kernel/Adam_1, train/beta1_power, train/beta2_power)]]\n\nCaused by op 'save/SaveV2', defined at:\n  File \"C:\\Users\\sdgeo\\AppData\\Local\\Programs\\Python\\Python36\\Lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\sdgeo\\AppData\\Local\\Programs\\Python\\Python36\\Lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"c:\\users\\sdgeo\\dropbox\\derlab~1\\data\\iremrppa\\env\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"c:\\users\\sdgeo\\dropbox\\derlab~1\\data\\iremrppa\\env\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"c:\\users\\sdgeo\\dropbox\\derlab~1\\data\\iremrppa\\env\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"c:\\users\\sdgeo\\dropbox\\derlab~1\\data\\iremrppa\\env\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 112, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\sdgeo\\AppData\\Local\\Programs\\Python\\Python36\\Lib\\asyncio\\base_events.py\", line 421, in run_forever\n    self._run_once()\n  File \"C:\\Users\\sdgeo\\AppData\\Local\\Programs\\Python\\Python36\\Lib\\asyncio\\base_events.py\", line 1426, in _run_once\n    handle._run()\n  File \"C:\\Users\\sdgeo\\AppData\\Local\\Programs\\Python\\Python36\\Lib\\asyncio\\events.py\", line 127, in _run\n    self._callback(*self._args)\n  File \"c:\\users\\sdgeo\\dropbox\\derlab~1\\data\\iremrppa\\env\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 102, in _handle_events\n    handler_func(fileobj, events)\n  File \"c:\\users\\sdgeo\\dropbox\\derlab~1\\data\\iremrppa\\env\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"c:\\users\\sdgeo\\dropbox\\derlab~1\\data\\iremrppa\\env\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"c:\\users\\sdgeo\\dropbox\\derlab~1\\data\\iremrppa\\env\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"c:\\users\\sdgeo\\dropbox\\derlab~1\\data\\iremrppa\\env\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"c:\\users\\sdgeo\\dropbox\\derlab~1\\data\\iremrppa\\env\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"c:\\users\\sdgeo\\dropbox\\derlab~1\\data\\iremrppa\\env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"c:\\users\\sdgeo\\dropbox\\derlab~1\\data\\iremrppa\\env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"c:\\users\\sdgeo\\dropbox\\derlab~1\\data\\iremrppa\\env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"c:\\users\\sdgeo\\dropbox\\derlab~1\\data\\iremrppa\\env\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"c:\\users\\sdgeo\\dropbox\\derlab~1\\data\\iremrppa\\env\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"c:\\users\\sdgeo\\dropbox\\derlab~1\\data\\iremrppa\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"c:\\users\\sdgeo\\dropbox\\derlab~1\\data\\iremrppa\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"c:\\users\\sdgeo\\dropbox\\derlab~1\\data\\iremrppa\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-5-0d97ea1da21e>\", line 3, in <module>\n    scores = cross_val_score_dnn(model, train_treatment_tensor, train_treatment_labels_tensor)\n  File \"C:\\Users\\sdgeo\\Dropbox\\Der Lab\\Data\\IremRPPA\\Utilities\\models.py\", line 167, in cross_val_score_dnn\n    model.fit(X_train_folds, y_train_folds)\n  File \"C:\\Users\\sdgeo\\Dropbox\\Der Lab\\Data\\IremRPPA\\Utilities\\models.py\", line 115, in fit\n    saver = tf.train.Saver()\n  File \"c:\\users\\sdgeo\\dropbox\\derlab~1\\data\\iremrppa\\env\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1311, in __init__\n    self.build()\n  File \"c:\\users\\sdgeo\\dropbox\\derlab~1\\data\\iremrppa\\env\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1320, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"c:\\users\\sdgeo\\dropbox\\derlab~1\\data\\iremrppa\\env\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1357, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"c:\\users\\sdgeo\\dropbox\\derlab~1\\data\\iremrppa\\env\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 806, in _build_internal\n    save_tensor = self._AddSaveOps(filename_tensor, saveables)\n  File \"c:\\users\\sdgeo\\dropbox\\derlab~1\\data\\iremrppa\\env\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 326, in _AddSaveOps\n    save = self.save_op(filename_tensor, saveables)\n  File \"c:\\users\\sdgeo\\dropbox\\derlab~1\\data\\iremrppa\\env\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 242, in save_op\n    tensors)\n  File \"c:\\users\\sdgeo\\dropbox\\derlab~1\\data\\iremrppa\\env\\lib\\site-packages\\tensorflow\\python\\ops\\gen_io_ops.py\", line 1793, in save_v2\n    shape_and_slices=shape_and_slices, tensors=tensors, name=name)\n  File \"c:\\users\\sdgeo\\dropbox\\derlab~1\\data\\iremrppa\\env\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"c:\\users\\sdgeo\\dropbox\\derlab~1\\data\\iremrppa\\env\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3290, in create_op\n    op_def=op_def)\n  File \"c:\\users\\sdgeo\\dropbox\\derlab~1\\data\\iremrppa\\env\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1654, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nUnknownError (see above for traceback): Failed to rename: /tmp/models/tf_logs_final/dnn_out-run-20180427200420/dnn_model.ckpt.index.tempstate3409807438837728086 to: /tmp/models/tf_logs_final/dnn_out-run-20180427200420/dnn_model.ckpt.index : Access is denied.\r\n; Input/output error\n\t [[Node: save/SaveV2 = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/SaveV2/tensor_names, save/SaveV2/shape_and_slices, batch_normalization/beta, batch_normalization/beta/Adam, batch_normalization/beta/Adam_1, batch_normalization/gamma, batch_normalization/gamma/Adam, batch_normalization/gamma/Adam_1, batch_normalization/moving_mean, batch_normalization/moving_variance, batch_normalization_1/beta, batch_normalization_1/beta/Adam, batch_normalization_1/beta/Adam_1, batch_normalization_1/gamma, batch_normalization_1/gamma/Adam, batch_normalization_1/gamma/Adam_1, batch_normalization_1/moving_mean, batch_normalization_1/moving_variance, batch_normalization_2/beta, batch_normalization_2/beta/Adam, batch_normalization_2/beta/Adam_1, batch_normalization_2/gamma, batch_normalization_2/gamma/Adam, batch_normalization_2/gamma/Adam_1, batch_normalization_2/moving_mean, batch_normalization_2/moving_variance, batch_normalization_3/beta, batch_normalization_3/beta/Adam, batch_normalization_3/beta/Adam_1, batch_normalization_3/gamma, batch_normalization_3/gamma/Adam, batch_normalization_3/gamma/Adam_1, batch_normalization_3/moving_mean, batch_normalization_3/moving_variance, hidden1/bias, hidden1/bias/Adam, hidden1/bias/Adam_1, hidden1/kernel, hidden1/kernel/Adam, hidden1/kernel/Adam_1, hidden2/bias, hidden2/bias/Adam, hidden2/bias/Adam_1, hidden2/kernel, hidden2/kernel/Adam, hidden2/kernel/Adam_1, hidden3/bias, hidden3/bias/Adam, hidden3/bias/Adam_1, hidden3/kernel, hidden3/kernel/Adam, hidden3/kernel/Adam_1, hidden4/bias, hidden4/bias/Adam, hidden4/bias/Adam_1, hidden4/kernel, hidden4/kernel/Adam, hidden4/kernel/Adam_1, logits/beta, logits/beta/Adam, logits/beta/Adam_1, logits/gamma, logits/gamma/Adam, logits/gamma/Adam_1, logits/moving_mean, logits/moving_variance, outputs/bias, outputs/bias/Adam, outputs/bias/Adam_1, outputs/kernel, outputs/kernel/Adam, outputs/kernel/Adam_1, train/beta1_power, train/beta2_power)]]\n"
     ]
    }
   ],
   "source": [
    "model = DNN_Model(log_dir=\"/tmp/models/tf_logs_final\")\n",
    "scores = cross_val_score_dnn(model, train_treatment_tensor, train_treatment_labels_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9461964750935339"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores\n",
    "final = np.mean(scores)\n",
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/models/current_model.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9233245501590468"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "with tf.Session(config=tf.ConfigProto(allow_soft_placement=True)) as sess:\n",
    "    saver.restore(sess, \"/tmp/models/current_model.ckpt\")\n",
    "    X_new_scaled = test_treatment_tensor\n",
    "    logits = tf.get_default_graph().get_tensor_by_name(\"dnn/logits/batchnorm/add_1:0\")\n",
    "    X_tensor = tf.get_default_graph().get_tensor_by_name(\"X_input:0\")\n",
    "    training = tf.get_default_graph().get_tensor_by_name(\"training:0\")\n",
    "    y_raw = logits.eval(feed_dict={training: False, X_tensor: X_new_scaled})\n",
    "    y_pred = np.argmax(y_raw, axis=1)\n",
    "    \n",
    "f1_score(y_pred, test_treatment_labels_tensor, average='macro') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
